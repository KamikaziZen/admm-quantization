{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176e4c93-1b61-491c-92af-be84a105574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce4e6c-e12b-4a07-86d8-ce03fdd6efa8",
   "metadata": {},
   "source": [
    "![Original-ResNet-18-Architecture.png](Original-ResNet-18-Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a198943c-8af6-4f9b-b6e0-61240f397772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/home/d.cherniuk/quantization_project/notebooks/../tensorly-private/tensorly/backend/pytorch_backend.py:127: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:859.)\n",
      "  solution, _ = torch.solve(matrix2, matrix1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if '../tensorly-private' not in sys.path:\n",
    "    sys.path.append('../tensorly-private')\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "tl.set_backend('pytorch')\n",
    "A = torch.rand(90, 80)\n",
    "_, (B,C) = parafac(A, rank=80, init='random', \n",
    "                   tol=1e-8, stop_criterion='rec_error_deviation', n_iter_max=5000)\n",
    "assert (B@C.T).shape == A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2905134-54de-452a-be14-fea34ce282a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009052125387825072"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.sum((B@C.T - A)**2) / torch.sum((A)**2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0015c719-f74d-4461-bedf-d6512306c358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1000,  0.5000,  0.9000,  ..., -1.0000,  0.5000,  0.8000],\n",
       "        [ 0.9000, -0.5000, -0.4000,  ...,  0.1000,  0.5000, -0.9000],\n",
       "        [ 0.3000, -0.7000,  0.7000,  ..., -0.6000,  0.5000,  0.4000],\n",
       "        ...,\n",
       "        [-0.7000,  0.0000, -0.5000,  ..., -1.0000, -0.7000, -0.8000],\n",
       "        [ 0.8000,  0.3000, -0.7000,  ..., -0.1000,  0.5000, -0.4000],\n",
       "        [ 0.1000,  0.6000, -0.7000,  ...,  0.8000,  0.7000,  0.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21f1cd95-37dd-4e13-8186-eeb140e2ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([90, 80]), 2, torch.Size([90, 50]), torch.Size([80, 50]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, len(factors), factors[0].shape, factors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700ac8cf-edd0-4b9d-9e11-f6ecab0ddc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model = resnet18(pretrained=True)\n",
    "orig_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd014fe-0fc2-4cb6-902b-00688a1ccdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1\n",
      "Original Shape: torch.Size([64, 3, 7, 7])\n",
      "Flattened Shape: torch.Size([64, 3, 49])\n",
      "Parameters: 9408\n",
      "Feasible ranks =  [40, 20, 10]\n",
      "\n",
      "Layer: layer1.0.conv1\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Parameters: 36864\n",
      "Feasible ranks =  [134, 67, 33]\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Parameters: 36864\n",
      "Feasible ranks =  [134, 67, 33]\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Parameters: 36864\n",
      "Feasible ranks =  [134, 67, 33]\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Parameters: 36864\n",
      "Feasible ranks =  [134, 67, 33]\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "Original Shape: torch.Size([128, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 64, 9])\n",
      "Parameters: 73728\n",
      "Feasible ranks =  [183, 91, 45]\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Parameters: 147456\n",
      "Feasible ranks =  [278, 139, 69]\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Parameters: 147456\n",
      "Feasible ranks =  [278, 139, 69]\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Parameters: 147456\n",
      "Feasible ranks =  [278, 139, 69]\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "Original Shape: torch.Size([256, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 128, 9])\n",
      "Parameters: 294912\n",
      "Feasible ranks =  [375, 187, 93]\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Parameters: 589824\n",
      "Feasible ranks =  [566, 283, 141]\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Parameters: 589824\n",
      "Feasible ranks =  [566, 283, 141]\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Parameters: 589824\n",
      "Feasible ranks =  [566, 283, 141]\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "Original Shape: torch.Size([512, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 256, 9])\n",
      "Parameters: 1179648\n",
      "Feasible ranks =  [759, 379, 189]\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Parameters: 2359296\n",
      "Feasible ranks =  [1141, 570, 285]\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Parameters: 2359296\n",
      "Feasible ranks =  [1141, 570, 285]\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Parameters: 2359296\n",
      "Feasible ranks =  [1141, 570, 285]\n",
      "\n",
      "Layer: fc\n",
      "Original Shape: torch.Size([1000, 512])\n",
      "Parameters: 512000\n",
      "Feasible ranks =  [169, 84, 42]\n"
     ]
    }
   ],
   "source": [
    "REDUCTION_RATES = [2, 4, 8]\n",
    "rank_map = {}\n",
    "\n",
    "X = orig_model.conv1.weight.detach()\n",
    "print('Layer: conv1')\n",
    "print('Original Shape:', X.shape)\n",
    "X = X.reshape((X.shape[0], X.shape[1], -1))\n",
    "print('Flattened Shape:', X.shape)\n",
    "print('Parameters:', X.numel())\n",
    "# print('Feasible ranks <', X.numel()/sum(list(X.shape))/REDUCTION_RATE)\n",
    "ranks = list(int(X.numel()/sum(list(X.shape))/rate) for rate in REDUCTION_RATES)\n",
    "print('Feasible ranks = ', ranks)\n",
    "print()\n",
    "rank_map['conv1'] = ranks\n",
    "\n",
    "for layer_name in ['layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', \n",
    "                   'layer2.0.conv1', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2',\n",
    "                   'layer3.0.conv1', 'layer3.0.conv2', 'layer3.1.conv1', 'layer3.1.conv2',\n",
    "                   'layer4.0.conv1', 'layer4.0.conv2', 'layer4.1.conv1', 'layer4.1.conv2']:\n",
    "    lname, lidx, ltype = layer_name.split('.')\n",
    "    lidx = int(lidx)\n",
    "    layer = orig_model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "    X = layer.weight.detach()\n",
    "    print('Layer:', layer_name)\n",
    "    print('Original Shape:', X.shape)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], -1))\n",
    "    print('Flattened Shape:', X.shape)\n",
    "    print('Parameters:', X.numel())\n",
    "    ranks = list(int(X.numel()/sum(list(X.shape))/rate) for rate in REDUCTION_RATES)\n",
    "    print('Feasible ranks = ', ranks)\n",
    "    print()\n",
    "    rank_map[layer_name] = ranks\n",
    "\n",
    "X = orig_model.fc.weight.detach()\n",
    "print('Layer: fc')\n",
    "print('Original Shape:', X.shape)\n",
    "print('Parameters:', X.numel())\n",
    "# print('Feasible rank < ', X.numel()/sum(list(X.shape))/rate)\n",
    "ranks = list(int(X.numel()/sum(list(X.shape))/rate) for rate in REDUCTION_RATES)\n",
    "print('Feasible ranks = ', ranks)\n",
    "rank_map['fc'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfb7975-0ce6-473e-b6d3-f29f90af446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': [40, 20, 10],\n",
       " 'layer1.0.conv1': [134, 67, 33],\n",
       " 'layer1.0.conv2': [134, 67, 33],\n",
       " 'layer1.1.conv1': [134, 67, 33],\n",
       " 'layer1.1.conv2': [134, 67, 33],\n",
       " 'layer2.0.conv1': [183, 91, 45],\n",
       " 'layer2.0.conv2': [278, 139, 69],\n",
       " 'layer2.1.conv1': [278, 139, 69],\n",
       " 'layer2.1.conv2': [278, 139, 69],\n",
       " 'layer3.0.conv1': [375, 187, 93],\n",
       " 'layer3.0.conv2': [566, 283, 141],\n",
       " 'layer3.1.conv1': [566, 283, 141],\n",
       " 'layer3.1.conv2': [566, 283, 141],\n",
       " 'layer4.0.conv1': [759, 379, 189],\n",
       " 'layer4.0.conv2': [1141, 570, 285],\n",
       " 'layer4.1.conv1': [1141, 570, 285],\n",
       " 'layer4.1.conv2': [1141, 570, 285],\n",
       " 'fc': [169, 84, 42]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a69b3b-2594-4d95-ae04-65faa9393a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark20",
   "language": "python",
   "name": "mark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
