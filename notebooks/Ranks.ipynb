{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176e4c93-1b61-491c-92af-be84a105574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce4e6c-e12b-4a07-86d8-ce03fdd6efa8",
   "metadata": {},
   "source": [
    "![Original-ResNet-18-Architecture.png](Original-ResNet-18-Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700ac8cf-edd0-4b9d-9e11-f6ecab0ddc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/kamikazi/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cc5b4f82854cf99e504573dc77fd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model = resnet18(pretrained=True)\n",
    "orig_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dbd014fe-0fc2-4cb6-902b-00688a1ccdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 3, 7, 7])\n",
      "Flattened Shape: torch.Size([64, 3, 49])\n",
      "Parameters: 9408\n",
      "Original MACs: tensor(118013952)\n",
      "Feasible ranks: [81, 40, 20, 16, 13, 11, 10]\n",
      "\n",
      "Layer: layer1.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Feasible MACs(%): [1860.03, 484.91, 132.86, 86.98, 62.54, 48.45, 38.05]\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Feasible MACs(%): [1860.03, 484.91, 132.86, 86.98, 62.54, 48.45, 38.05]\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Feasible MACs(%): [1860.03, 484.91, 132.86, 86.98, 62.54, 48.45, 38.05]\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Feasible MACs(%): [1860.03, 484.91, 132.86, 86.98, 62.54, 48.45, 38.05]\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 73728\n",
      "Original MACs: tensor(57802752)\n",
      "Feasible ranks: [366, 183, 91, 73, 61, 52, 45]\n",
      "Feasible MACs(%): [1825.83, 504.11, 148.48, 103.07, 77.19, 60.09, 48.16]\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Feasible MACs(%): [1983.34, 519.97, 142.06, 94.47, 67.63, 51.81, 41.04]\n",
      "\n",
      "Layer: layer2.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 64, 1, 1])\n",
      "Flattened Shape: torch.Size([128, 64])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 8192\n",
      "Original MACs: tensor(6422528)\n",
      "Feasible ranks: [42, 21, 10, 8, 7, 6, 5]\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Feasible MACs(%): [1983.34, 519.97, 142.06, 94.47, 67.63, 51.81, 41.04]\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Feasible MACs(%): [1983.34, 519.97, 142.06, 94.47, 67.63, 51.81, 41.04]\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 294912\n",
      "Original MACs: tensor(57802752)\n",
      "Feasible ranks: [750, 375, 187, 150, 125, 107, 93]\n",
      "Feasible MACs(%): [1911.93, 526.81, 155.41, 107.73, 80.24, 62.8, 50.61]\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Feasible MACs(%): [2053.56, 537.96, 146.77, 97.55, 70.25, 53.53, 42.58]\n",
      "\n",
      "Layer: layer3.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 128, 1, 1])\n",
      "Flattened Shape: torch.Size([256, 128])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 32768\n",
      "Original MACs: tensor(6422528)\n",
      "Feasible ranks: [85, 42, 21, 17, 14, 12, 10]\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Feasible MACs(%): [2053.56, 537.96, 146.77, 97.55, 70.25, 53.53, 42.58]\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Feasible MACs(%): [2053.56, 537.96, 146.77, 97.55, 70.25, 53.53, 42.58]\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 1179648\n",
      "Original MACs: tensor(57802752)\n",
      "Feasible ranks: [1518, 759, 379, 303, 253, 216, 189]\n",
      "Feasible MACs(%): [1955.72, 538.34, 158.94, 109.5, 81.78, 63.72, 51.86]\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Feasible MACs(%): [2087.34, 546.15, 148.68, 99.11, 71.58, 54.69, 43.35]\n",
      "\n",
      "Layer: layer4.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 256, 1, 1])\n",
      "Flattened Shape: torch.Size([512, 256])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 131072\n",
      "Original MACs: tensor(6422528)\n",
      "Feasible ranks: [170, 85, 42, 34, 28, 24, 21]\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Feasible MACs(%): [2087.34, 546.15, 148.68, 99.11, 71.58, 54.69, 43.35]\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: tensor(115605504)\n",
      "Feasible ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Feasible MACs(%): [2087.34, 546.15, 148.68, 99.11, 71.58, 54.69, 43.35]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "REDUCTION_RATES = [1, 2, 4, 5, 6, 7, 8]\n",
    "rank_map = {}\n",
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# original macs = C_i * W_k * H_k * C_o * W_o * H_o\n",
    "# reduced macs = rank * C_i * W_i * H_i + rank**2 * W_k * H_k * W_o * H_o + rank * C_o * W_o * H_o\n",
    "layer = orig_model.conv1\n",
    "weight = orig_model.conv1.weight.detach()\n",
    "bias = orig_model.conv1.bias\n",
    "with torch.no_grad(): y = layer(dummy_input)\n",
    "c1 = layer.in_channels * dummy_input.shape[-1] * dummy_input.shape[-2]\n",
    "c2 = layer.kernel_size[0] * layer.kernel_size[1] * y.shape[-1] * y.shape[-2]\n",
    "c3 = layer.out_channels * y.shape[-1] * y.shape[-2]\n",
    "print('Layer: conv1')\n",
    "print('bias:', bias is not None)\n",
    "print('Original Shape:', weight.shape)\n",
    "weight = weight.reshape((weight.shape[0], weight.shape[1], -1))\n",
    "print('Flattened Shape:', weight.shape)\n",
    "print('Parameters:', weight.numel())\n",
    "orig_macs = torch.tensor(weight.shape).prod() * y.shape[-1] * y.shape[-2]\n",
    "print('Original MACs:', orig_macs)\n",
    "# print('Feasible ranks <', X.numel()/sum(list(X.shape))/REDUCTION_RATE)\n",
    "ranks = list(int(weight.numel()/sum(list(weight.shape))/rate) for rate in REDUCTION_RATES)\n",
    "print('Feasible ranks:', ranks)\n",
    "# macs = [((rank * c1 + rank**2 * c2 + rank * c3) * 100/orig_macs).item() for rank in ranks]\n",
    "# print('Feasible MACs(%):', [round(mac, 2) for mac in macs])\n",
    "print()\n",
    "rank_map['conv1'] = ranks\n",
    "y = orig_model.maxpool(y)\n",
    "\n",
    "for layer_name in ['layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', \n",
    "                   'layer2.0.conv1', 'layer2.0.conv2', 'layer2.0.downsample', 'layer2.1.conv1', 'layer2.1.conv2',\n",
    "                   'layer3.0.conv1', 'layer3.0.conv2', 'layer3.0.downsample', 'layer3.1.conv1', 'layer3.1.conv2',\n",
    "                   'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample', 'layer4.1.conv1', 'layer4.1.conv2']:\n",
    "    lname, lidx, ltype = layer_name.split('.')\n",
    "    lidx = int(lidx)\n",
    "    layer = orig_model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "    if ltype == 'downsample': layer = layer[0]\n",
    "    weight = layer.weight.detach()\n",
    "    bias = orig_model.conv1.bias\n",
    "    print('Layer:', layer_name)\n",
    "    print('bias:', bias is not None)\n",
    "    print('Original Shape:', weight.shape)\n",
    "    weight = weight.reshape((weight.shape[0], weight.shape[1], -1))\n",
    "    if ltype == 'downsample': weight = weight.reshape((weight.shape[0], weight.shape[1]))\n",
    "    print('Flattened Shape:', weight.shape)\n",
    "    \n",
    "    print('Input shape:', y.shape)\n",
    "    c1 = layer.in_channels * y.shape[-1] * y.shape[-2]\n",
    "    if layer_name.endswith('.0.conv1'): \n",
    "        with torch.no_grad(): y = layer(y)\n",
    "    c2 = layer.kernel_size[0] * layer.kernel_size[1] * y.shape[-1] * y.shape[-2]\n",
    "    c3 = layer.out_channels * y.shape[-1] * y.shape[-2]\n",
    "    print('Output shape:', y.shape)\n",
    "    \n",
    "    print('Parameters:', weight.numel())\n",
    "    orig_macs = torch.tensor(weight.shape).prod() * y.shape[-1] * y.shape[-2]\n",
    "    print('Original MACs:', orig_macs)\n",
    "    ranks = list(int(weight.numel()/sum(list(weight.shape))/rate) for rate in REDUCTION_RATES)\n",
    "    print('Feasible ranks:', ranks)\n",
    "    if ltype != 'downsample': \n",
    "        macs = [((rank * c1 + rank**2 * c2 + rank * c3) * 100/orig_macs).item() for rank in ranks]\n",
    "        print('Feasible MACs(%):', [round(mac, 2) for mac in macs])\n",
    "    print()\n",
    "    rank_map[layer_name] = ranks\n",
    "    \n",
    "\n",
    "# X = orig_model.fc.weight.detach()\n",
    "# bias = orig_model.conv1.bias\n",
    "# print('Layer: fc')\n",
    "# print('Original Shape:', X.shape)\n",
    "# print('Parameters:', X.numel())\n",
    "# print('bias:', bias is not None)\n",
    "# # print('Feasible rank < ', X.numel()/sum(list(X.shape))/rate)\n",
    "# ranks = list(int(X.numel()/sum(list(X.shape))/rate) for rate in REDUCTION_RATES)\n",
    "# print('Feasible ranks = ', ranks)\n",
    "# rank_map['fc'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfb7975-0ce6-473e-b6d3-f29f90af446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': [81, 40, 20, 10],\n",
       " 'layer1.0.conv1': [269, 134, 67, 33],\n",
       " 'layer1.0.conv2': [269, 134, 67, 33],\n",
       " 'layer1.1.conv1': [269, 134, 67, 33],\n",
       " 'layer1.1.conv2': [269, 134, 67, 33],\n",
       " 'layer2.0.conv1': [366, 183, 91, 45],\n",
       " 'layer2.0.conv2': [556, 278, 139, 69],\n",
       " 'layer2.0.downsample': [42, 21, 10, 5],\n",
       " 'layer2.1.conv1': [556, 278, 139, 69],\n",
       " 'layer2.1.conv2': [556, 278, 139, 69],\n",
       " 'layer3.0.conv1': [750, 375, 187, 93],\n",
       " 'layer3.0.conv2': [1132, 566, 283, 141],\n",
       " 'layer3.0.downsample': [85, 42, 21, 10],\n",
       " 'layer3.1.conv1': [1132, 566, 283, 141],\n",
       " 'layer3.1.conv2': [1132, 566, 283, 141],\n",
       " 'layer4.0.conv1': [1518, 759, 379, 189],\n",
       " 'layer4.0.conv2': [2283, 1141, 570, 285],\n",
       " 'layer4.0.downsample': [170, 85, 42, 21],\n",
       " 'layer4.1.conv1': [2283, 1141, 570, 285],\n",
       " 'layer4.1.conv2': [2283, 1141, 570, 285],\n",
       " 'fc': [338, 169, 84, 42]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a69b3b-2594-4d95-ae04-65faa9393a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
