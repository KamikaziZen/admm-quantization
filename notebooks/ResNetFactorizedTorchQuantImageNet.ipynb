{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5abc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085ed3b4-eb16-4799-bef8-6097ced96443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78892c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.quantization import MovingAverageMinMaxObserver,HistogramObserver\n",
    "\n",
    "from source.data import get_imagenet_test_loader, get_imagenet_train_val_loaders\n",
    "from source.eval import accuracy\n",
    "from source.admm import build_cp_layer\n",
    "from source.utils import bncalibrate_model\n",
    "from source.models import ResNet18Quant\n",
    "from source.rank_map import get_rank_map\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fe815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, use_cuda):\n",
    "    batch_size = train_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in train_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            print(batch_cntr * batch_size)\n",
    "            if (batch_cntr * batch_size) >= samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701597d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bdd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b984b9-0930-4586-bd2f-a2a638f59b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'admm'\n",
    "qscheme = 'tensor_affine'\n",
    "bits = 8\n",
    "eps = 0.003\n",
    "decomp = 'cp3'\n",
    "rank_map = get_rank_map(eps, decomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b8c88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "# model = torch.load('eps0.003_calibrated')\n",
    "# weights = ResNet18_Weights.verify(ResNet18_Weights.IMAGENET1K_V1)\n",
    "# model = ResNet18Quant(num_classes=len(weights.meta[\"categories\"]))\n",
    "# model.load_state_dict(weights.get_state_dict(progress=True))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e628c071-6cbd-4023-bb5a-f65722ca48de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814073344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "orig_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    orig_macs += x[0]\n",
    "orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f8e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 8bit_tensor_affine/factors_admm_seed42/layer1.0.conv1_admm_random_rank_64\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer1.0.conv2_admm_random_rank_61\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer1.1.conv1_admm_random_rank_78\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer1.1.conv2_admm_random_rank_73\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer2.0.conv1_admm_random_rank_133\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer2.0.conv2_admm_random_rank_146\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer2.1.conv1_admm_random_rank_173\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer2.1.conv2_admm_random_rank_131\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer3.0.conv1_admm_random_rank_159\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer3.0.conv2_admm_random_rank_248\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer3.1.conv1_admm_random_rank_268\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer3.1.conv2_admm_random_rank_249\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer4.0.conv1_admm_random_rank_363\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer4.0.conv2_admm_random_rank_752\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer4.1.conv1_admm_random_rank_574\n",
      "loading 8bit_tensor_affine/factors_admm_seed42/layer4.1.conv2_admm_random_rank_282\n"
     ]
    }
   ],
   "source": [
    "for module in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    for layer_path in [f'{module}.0.conv1', f'{module}.0.conv2', \n",
    "#                        f'{module}.0.downsample',\n",
    "                       f'{module}.1.conv1', f'{module}.1.conv2']:\n",
    "        # there is no layer1.0.downsample layer\n",
    "        if layer_path == 'layer1.0.downsample': continue\n",
    "            \n",
    "        lname, lidx, ltype = layer_path.split('.')\n",
    "        lidx = int(lidx)\n",
    "        layer = model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "        kernel_size = layer.kernel_size\n",
    "        stride = layer.stride\n",
    "        padding = layer.padding\n",
    "        cin = layer.in_channels\n",
    "        cout = layer.out_channels\n",
    "        rank = rank_map[layer_path]\n",
    "        bias = layer.bias\n",
    "        if bias is not None: bias = bias.detach()\n",
    "        \n",
    "        print(f'loading {bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}')\n",
    "        A = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_0.pt').to(device)\n",
    "        assert A.dtype == torch.float \n",
    "        B = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_1.pt').to(device)\n",
    "        C = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_2.pt').to(device)\n",
    "\n",
    "        model.__getattr__(lname)[lidx].__setattr__(\n",
    "            ltype, build_cp_layer(rank, [A,B,C], bias, cin, cout, kernel_size, padding, stride).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5969e1a-1779-43ab-9cb0-25945ff90c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3318769249276836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "redc_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    redc_macs += x[0]\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6dcc0bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:48<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced9c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2459 [01:48<3:30:33,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.12 s, sys: 2.89 s, total: 10 s\n",
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_samples = 10000\n",
    "model = bncalibrate_model(model, train_loader, num_samples=num_samples, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd2a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6274"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da0938",
   "metadata": {},
   "source": [
    "# Torch Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b30eeee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_affine, dtype=torch.qint8){})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model.qconfig = torch.quantization.QConfig(\n",
    "  activation=HistogramObserver.with_args(reduce_range=True, dtype=torch.quint8, qscheme=torch.per_tensor_affine),\n",
    "  weight=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_affine, dtype=torch.qint8)\n",
    ")\n",
    "model.qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08bd1468-8596-4ae6-9f1b-4b0e4cbabc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['conv1', 'bn1', 'relu'],\n",
       " ['layer1.0.conv1.conv3', 'layer1.0.bn1', 'layer1.0.relu1'],\n",
       " ['layer1.1.conv1.conv3', 'layer1.1.bn1', 'layer1.1.relu1'],\n",
       " ['layer2.0.conv1.conv3', 'layer2.0.bn1', 'layer2.0.relu1'],\n",
       " ['layer2.1.conv1.conv3', 'layer2.1.bn1', 'layer2.1.relu1'],\n",
       " ['layer3.0.conv1.conv3', 'layer3.0.bn1', 'layer3.0.relu1'],\n",
       " ['layer3.1.conv1.conv3', 'layer3.1.bn1', 'layer3.1.relu1'],\n",
       " ['layer4.0.conv1.conv3', 'layer4.0.bn1', 'layer4.0.relu1'],\n",
       " ['layer4.1.conv1.conv3', 'layer4.1.bn1', 'layer4.1.relu1'],\n",
       " ['layer1.0.conv2.conv3', 'layer1.0.bn2'],\n",
       " ['layer1.1.conv2.conv3', 'layer1.1.bn2'],\n",
       " ['layer2.0.conv2.conv3', 'layer2.0.bn2'],\n",
       " ['layer2.1.conv2.conv3', 'layer2.1.bn2'],\n",
       " ['layer3.0.conv2.conv3', 'layer3.0.bn2'],\n",
       " ['layer3.1.conv2.conv3', 'layer3.1.bn2'],\n",
       " ['layer4.0.conv2.conv3', 'layer4.0.bn2'],\n",
       " ['layer4.1.conv2.conv3', 'layer4.1.bn2'],\n",
       " ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
       " ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
       " ['layer4.0.downsample.0', 'layer4.0.downsample.1']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules_to_fuse = [\n",
    "    ['conv1', 'bn1', 'relu'],\n",
    "    *([f'layer{i}.{j}.conv1.conv3', f'layer{i}.{j}.bn1', f'layer{i}.{j}.relu1'] for i in (1,2,3,4) for j in (0,1)),\n",
    "    *([f'layer{i}.{j}.conv2.conv3', f'layer{i}.{j}.bn2'] for i in (1,2,3,4) for j in (0,1)),\n",
    "    *([f'layer{i}.0.downsample.0', f'layer{i}.0.downsample.1'] for i in (2,3,4))\n",
    "]\n",
    "modules_to_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35e3740b-6402-42fe-9b22-67b0f540c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.quantization.fuse_modules(model, modules_to_fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d63a02d-f60c-443f-9316-2d80a7232ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torch/ao/quantization/observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = torch.quantization.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6899458-c51d-42c6-b8c8-bed2d1abfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32012e69-5f2b-41f3-918b-5414957f9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can move to gpu for faster quantization calbration\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36fe35a4-d185-400f-9e78-aeb10de2d127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:28,  7.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# quantiation calibration on 2000 samples of train dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (train_x, _) in tqdm(enumerate(train_loader)):\n",
    "        _ = model(train_x.cuda())\n",
    "        if idx * train_loader.batch_size >= 2000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "892f7300-e959-4b92-a563-fdd30735f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to move to cpu for quantization conversion\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a05caa29-b64d-425f-90ad-6a622d35d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ee3bdbc-1d82-4310-8f3d-047dc64a9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:44:08<00:00, 62.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52988"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "accuracy(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f6edc-e473-4995-8bb8-b2cc60f648bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark23",
   "language": "python",
   "name": "mark23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
