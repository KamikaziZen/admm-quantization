{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5abc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085ed3b4-eb16-4799-bef8-6097ced96443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78892c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "\n",
    "from source.data import get_imagenet_test_loader, get_imagenet_train_val_loaders\n",
    "from source.eval import accuracy\n",
    "# from source.admm import build_cp_layer\n",
    "from source.utils import bncalibrate_model\n",
    "from source.rank_map import get_rank_map\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30ced4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.9.1+cu111', '0.10.1+cu111')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torch.__version__, torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fe815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, use_cuda, dataloader):\n",
    "    batch_size = train_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in train_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            print(batch_cntr * batch_size)\n",
    "            if (batch_cntr * batch_size) >= samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701597d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=32,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bdd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=32,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5282a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'parafac_epc'\n",
    "qscheme = 'tensor_affine'\n",
    "bits = 8\n",
    "eps = 0.0005\n",
    "decomp = 'cp3-epc'\n",
    "rank_map = get_rank_map(eps, decomp)\n",
    "num_samples = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b8c88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model m=parafac_epc_b=8_e=0.0005_d=cp3-epc_affine.calibrated_2048\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"m={method}_b={bits}_e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\"\n",
    "# model = resnet18(pretrained=True).to(device)\n",
    "print(f\"loading model {model_name}\")\n",
    "model = torch.load('../checkpoints/'+model_name)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e628c071-6cbd-4023-bb5a-f65722ca48de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814073344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "orig_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    orig_macs += x[0]\n",
    "orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f8e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer1.0.conv1_parafac_epc_random_rank_101_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer1.0.conv2_parafac_epc_random_rank_90_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer1.1.conv1_parafac_epc_random_rank_133_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer1.1.conv2_parafac_epc_random_rank_107_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer2.0.conv1_parafac_epc_random_rank_249_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer2.0.conv2_parafac_epc_random_rank_293_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer2.1.conv1_parafac_epc_random_rank_302_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer2.1.conv2_parafac_epc_random_rank_212_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer3.0.conv1_parafac_epc_random_rank_247_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer3.0.conv2_parafac_epc_random_rank_438_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer3.1.conv1_parafac_epc_random_rank_492_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer3.1.conv2_parafac_epc_random_rank_396_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer4.0.conv1_parafac_epc_random_rank_605_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer4.0.conv2_parafac_epc_random_rank_1300_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer4.1.conv1_parafac_epc_random_rank_1200_mode_\n",
      "loading factors: ../8bit_tensor_affine/factors_parafac_epc_seed42/layer4.1.conv2_parafac_epc_random_rank_850_mode_\n"
     ]
    }
   ],
   "source": [
    "for module in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    for layer_path in [f'{module}.0.conv1', f'{module}.0.conv2', \n",
    "#                        f'{module}.0.downsample',\n",
    "                       f'{module}.1.conv1', f'{module}.1.conv2']:\n",
    "        # there is no layer1.0.downsample layer\n",
    "        if layer_path == 'layer1.0.downsample': continue\n",
    "        # layer1.0.conv1 is crusial\n",
    "#         if layer_path == 'layer1.0.conv1': continue\n",
    "            \n",
    "        lname, lidx, ltype = layer_path.split('.')\n",
    "        lidx = int(lidx)\n",
    "        layer = model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "        kernel_size = layer.kernel_size\n",
    "        stride = layer.stride\n",
    "        padding = layer.padding\n",
    "        cin = layer.in_channels\n",
    "        cout = layer.out_channels\n",
    "        rank = rank_map[layer_path]\n",
    "        bias = layer.bias\n",
    "        if bias is not None: bias = bias.detach()\n",
    "        \n",
    "        factor_name = os.path.join(f\"../{bits}bit_{qscheme}\",\n",
    "                                   f\"factors_{method}_seed{seed}\", \n",
    "                                   f\"{layer_path}_{method}_random_rank_{rank}_mode_\")\n",
    "        print('loading factors:', factor_name)\n",
    "        A = torch.load(factor_name+'0.pt').float().to(device)\n",
    "        assert A.dtype == torch.float \n",
    "        B = torch.load(factor_name+'1.pt').float().to(device)\n",
    "        C = torch.load(factor_name+'2.pt').float().to(device)\n",
    "    \n",
    "        model.__getattr__(lname)[lidx].__setattr__(\n",
    "            ltype, build_cp_layer(rank, [A,B,C], bias, cin, cout, kernel_size, padding, stride).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5969e1a-1779-43ab-9cb0-25945ff90c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5268461466351826"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "redc_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    redc_macs += x[0]\n",
    "# redc_macs / orig_macs\n",
    "redc_macs / 1814073344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6dcc0bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [01:40<00:00, 15.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19962387964148529"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced9c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 65/38435 [00:22<3:43:02,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "model = bncalibrate_model(model, train_loader, num_samples=num_samples, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd2a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [01:38<00:00, 15.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6469070102432779"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, f\"m={method}_b={bits}_e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\")\n",
    "torch.save(model, '../checkpoints/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d98798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m=admm_b=8_e=0.001_d=cp3_affine.calibrated_10000'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da0938",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7184655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-23 18:54:54,035 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2023-01-23 18:54:54,036 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2023-01-23 18:54:54,036 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2023-01-23 18:54:54,037 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2023-01-23 18:54:54,037 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2023-01-23 18:54:54,038 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2023-01-23 18:54:54,038 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2023-01-23 18:54:54,039 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2023-01-23 18:54:54,039 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2023-01-23 18:54:54,040 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2023-01-23 18:54:54,040 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2023-01-23 18:54:54,041 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2023-01-23 18:54:54,041 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2023-01-23 18:54:54,042 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2023-01-23 18:54:54,042 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2023-01-23 18:54:54,043 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf4f31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-23 18:54:58,828 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2023-01-23 18:54:58,829 - Utils - INFO - ...... subset to store [Conv_4, BatchNormalization_5]\n",
      "2023-01-23 18:54:58,829 - Utils - INFO - ...... subset to store [Conv_9, BatchNormalization_10]\n",
      "2023-01-23 18:54:58,830 - Utils - INFO - ...... subset to store [Conv_15, BatchNormalization_16]\n",
      "2023-01-23 18:54:58,830 - Utils - INFO - ...... subset to store [Conv_20, BatchNormalization_21]\n",
      "2023-01-23 18:54:58,830 - Utils - INFO - ...... subset to store [Conv_26, BatchNormalization_27]\n",
      "2023-01-23 18:54:58,831 - Utils - INFO - ...... subset to store [Conv_31, BatchNormalization_32]\n",
      "2023-01-23 18:54:58,831 - Utils - INFO - ...... subset to store [Conv_39, BatchNormalization_40]\n",
      "2023-01-23 18:54:58,832 - Utils - INFO - ...... subset to store [Conv_44, BatchNormalization_45]\n",
      "2023-01-23 18:54:58,832 - Utils - INFO - ...... subset to store [Conv_50, BatchNormalization_51]\n",
      "2023-01-23 18:54:58,832 - Utils - INFO - ...... subset to store [Conv_55, BatchNormalization_56]\n",
      "2023-01-23 18:54:58,833 - Utils - INFO - ...... subset to store [Conv_63, BatchNormalization_64]\n",
      "2023-01-23 18:54:58,833 - Utils - INFO - ...... subset to store [Conv_68, BatchNormalization_69]\n",
      "2023-01-23 18:54:58,833 - Utils - INFO - ...... subset to store [Conv_74, BatchNormalization_75]\n",
      "2023-01-23 18:54:58,834 - Utils - INFO - ...... subset to store [Conv_79, BatchNormalization_80]\n",
      "2023-01-23 18:54:58,834 - Utils - INFO - ...... subset to store [Conv_87, BatchNormalization_88]\n",
      "2023-01-23 18:54:58,835 - Utils - INFO - ...... subset to store [Conv_92, BatchNormalization_93]\n",
      "2023-01-23 18:54:58,835 - Utils - INFO - ...... subset to store [Conv_81, BatchNormalization_82]\n",
      "2023-01-23 18:54:58,835 - Utils - INFO - ...... subset to store [Conv_57, BatchNormalization_58]\n",
      "2023-01-23 18:54:58,836 - Utils - INFO - ...... subset to store [Conv_33, BatchNormalization_34]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20191c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-23 18:55:05,749 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-23 18:55:05,769 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-23 18:55:05,769 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-23 18:55:05,770 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-23 18:55:05,776 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-23 18:55:05,776 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-23 18:55:05,777 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-23 18:55:05,777 - Utils - INFO - ...... subset to store [Conv_3, Relu_4]\n",
      "2023-01-23 18:55:05,777 - Utils - INFO - ...... subset to store [Add_8, Relu_9]\n",
      "2023-01-23 18:55:05,778 - Utils - INFO - ...... subset to store [Add_8, Relu_9]\n",
      "2023-01-23 18:55:05,778 - Utils - INFO - ...... subset to store [Conv_12, Relu_13]\n",
      "2023-01-23 18:55:05,779 - Utils - INFO - ...... subset to store [Conv_12, Relu_13]\n",
      "2023-01-23 18:55:05,779 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-23 18:55:05,779 - Utils - INFO - ...... subset to store [Add_17, Relu_18]\n",
      "2023-01-23 18:55:05,780 - Utils - INFO - ...... subset to store [Conv_21, Relu_22]\n",
      "2023-01-23 18:55:05,780 - Utils - INFO - ...... subset to store [Conv_21, Relu_22]\n",
      "2023-01-23 18:55:05,780 - Utils - INFO - ...... subset to store [Add_27, Relu_28]\n",
      "2023-01-23 18:55:05,781 - Utils - INFO - ...... subset to store [Add_27, Relu_28]\n",
      "2023-01-23 18:55:05,781 - Utils - INFO - ...... subset to store [Conv_31, Relu_32]\n",
      "2023-01-23 18:55:05,781 - Utils - INFO - ...... subset to store [Conv_31, Relu_32]\n",
      "2023-01-23 18:55:05,782 - Utils - INFO - ...... subset to store [Add_36, Relu_37]\n",
      "2023-01-23 18:55:05,782 - Utils - INFO - ...... subset to store [Add_36, Relu_37]\n",
      "2023-01-23 18:55:05,782 - Utils - INFO - ...... subset to store [Conv_40, Relu_41]\n",
      "2023-01-23 18:55:05,783 - Utils - INFO - ...... subset to store [Conv_40, Relu_41]\n",
      "2023-01-23 18:55:05,783 - Utils - INFO - ...... subset to store [Add_46, Relu_47]\n",
      "2023-01-23 18:55:05,784 - Utils - INFO - ...... subset to store [Add_46, Relu_47]\n",
      "2023-01-23 18:55:05,784 - Utils - INFO - ...... subset to store [Conv_50, Relu_51]\n",
      "2023-01-23 18:55:05,784 - Utils - INFO - ...... subset to store [Conv_50, Relu_51]\n",
      "2023-01-23 18:55:05,785 - Utils - INFO - ...... subset to store [Add_55, Relu_56]\n",
      "2023-01-23 18:55:05,785 - Utils - INFO - ...... subset to store [Add_55, Relu_56]\n",
      "2023-01-23 18:55:05,785 - Utils - INFO - ...... subset to store [Conv_59, Relu_60]\n",
      "2023-01-23 18:55:05,786 - Utils - INFO - ...... subset to store [Conv_59, Relu_60]\n",
      "2023-01-23 18:55:05,786 - Utils - INFO - ...... subset to store [Add_65, Relu_66]\n",
      "2023-01-23 18:55:05,786 - Utils - INFO - ...... subset to store [Add_65, Relu_66]\n",
      "2023-01-23 18:55:05,787 - Utils - INFO - ...... subset to store [Conv_69, Relu_70]\n",
      "2023-01-23 18:55:05,787 - Utils - INFO - ...... subset to store [Conv_69, Relu_70]\n",
      "2023-01-23 18:55:05,788 - Utils - INFO - ...... subset to store [Add_74, Relu_75]\n",
      "2023-01-23 18:55:05,788 - Utils - INFO - ...... subset to store [Add_74, Relu_75]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "#                            quant_scheme=QuantScheme.post_training_tf,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8ef22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e356f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:43<00:00,  1.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00096"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post_training_tf_enchanced\n",
    "accuracy(sim.model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395feece",
   "metadata": {},
   "source": [
    "# AdaRound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b523d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:08:06,007 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2023-01-26 18:08:06,008 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2023-01-26 18:08:06,009 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2023-01-26 18:08:06,009 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2023-01-26 18:08:06,010 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2023-01-26 18:08:06,010 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2023-01-26 18:08:06,011 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2023-01-26 18:08:06,011 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2023-01-26 18:08:06,012 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2023-01-26 18:08:06,012 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2023-01-26 18:08:06,013 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2023-01-26 18:08:06,013 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2023-01-26 18:08:06,014 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2023-01-26 18:08:06,014 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2023-01-26 18:08:06,015 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2023-01-26 18:08:06,015 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5fe6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:08:07,396 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2023-01-26 18:08:07,398 - Utils - INFO - ...... subset to store [Conv_6, BatchNormalization_7]\n",
      "2023-01-26 18:08:07,398 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2023-01-26 18:08:07,399 - Utils - INFO - ...... subset to store [Conv_17, BatchNormalization_18]\n",
      "2023-01-26 18:08:07,399 - Utils - INFO - ...... subset to store [Conv_22, BatchNormalization_23]\n",
      "2023-01-26 18:08:07,399 - Utils - INFO - ...... subset to store [Conv_28, BatchNormalization_29]\n",
      "2023-01-26 18:08:07,400 - Utils - INFO - ...... subset to store [Conv_33, BatchNormalization_34]\n",
      "2023-01-26 18:08:07,400 - Utils - INFO - ...... subset to store [Conv_41, BatchNormalization_42]\n",
      "2023-01-26 18:08:07,401 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2023-01-26 18:08:07,401 - Utils - INFO - ...... subset to store [Conv_52, BatchNormalization_53]\n",
      "2023-01-26 18:08:07,401 - Utils - INFO - ...... subset to store [Conv_57, BatchNormalization_58]\n",
      "2023-01-26 18:08:07,402 - Utils - INFO - ...... subset to store [Conv_65, BatchNormalization_66]\n",
      "2023-01-26 18:08:07,402 - Utils - INFO - ...... subset to store [Conv_70, BatchNormalization_71]\n",
      "2023-01-26 18:08:07,402 - Utils - INFO - ...... subset to store [Conv_76, BatchNormalization_77]\n",
      "2023-01-26 18:08:07,403 - Utils - INFO - ...... subset to store [Conv_81, BatchNormalization_82]\n",
      "2023-01-26 18:08:07,403 - Utils - INFO - ...... subset to store [Conv_89, BatchNormalization_90]\n",
      "2023-01-26 18:08:07,404 - Utils - INFO - ...... subset to store [Conv_94, BatchNormalization_95]\n",
      "2023-01-26 18:08:07,404 - Utils - INFO - ...... subset to store [Conv_83, BatchNormalization_84]\n",
      "2023-01-26 18:08:07,404 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2023-01-26 18:08:07,405 - Utils - INFO - ...... subset to store [Conv_35, BatchNormalization_36]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b870d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AdaroundParameters(data_loader=val_loader, \n",
    "                            num_batches=2048//val_loader.batch_size, \n",
    "                            default_num_iterations=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbc5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224).cuda()\n",
    "# adaround_path = f\"adaround_e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\"\n",
    "adaround_path = 'adaround'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d799506",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./adaround/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f70370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(adaround_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ae03229",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db1e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.68 µs\n",
      "2023-01-26 18:50:09,055 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-26 18:50:09,073 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-26 18:50:09,074 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-26 18:50:09,074 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-26 18:50:09,080 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-26 18:50:09,080 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-26 18:50:09,081 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-26 18:50:09,081 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-26 18:50:09,081 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-26 18:50:09,082 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-26 18:50:09,082 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-26 18:50:09,083 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-26 18:50:09,083 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-26 18:50:09,083 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-26 18:50:09,084 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-26 18:50:09,084 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-26 18:50:09,084 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-26 18:50:09,085 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-26 18:50:09,085 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-26 18:50:09,085 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-26 18:50:09,086 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-26 18:50:09,086 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-26 18:50:09,086 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-26 18:50:09,087 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-26 18:50:09,087 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-26 18:50:09,087 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-26 18:50:09,088 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-26 18:50:09,088 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-26 18:50:09,089 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-26 18:50:09,089 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-26 18:50:09,089 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-26 18:50:09,090 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-26 18:50:09,090 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-26 18:50:09,090 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-26 18:50:09,091 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-26 18:50:09,091 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-26 18:50:09,091 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-26 18:50:09,092 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-26 18:50:19,124 - Utils - INFO - Caching 64 batches from data loader at path location: /tmp/adaround/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:50:19,719 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:51:56,959 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:52:35,109 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:53:16,824 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:54:02,695 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:54:42,592 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:55:22,776 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:56:05,058 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:56:48,063 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:57:36,523 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:58:27,050 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:59:06,338 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 18:59:50,038 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:00:34,139 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:01:31,933 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:02:19,214 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:03:02,076 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:03:43,150 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:04:20,149 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:05:04,004 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:05:42,157 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:06:23,538 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:07:00,848 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:07:45,827 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:08:26,240 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:09:01,432 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:09:43,797 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:10:24,991 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:10:59,740 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:11:37,234 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:12:12,170 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:12:45,600 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:13:28,417 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:14:09,223 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:14:44,750 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:15:18,826 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:16:02,791 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:16:38,454 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:17:12,126 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:17:55,460 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:18:32,029 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:19:06,494 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:19:49,831 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:20:31,178 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:21:04,885 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:21:48,607 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:22:25,507 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:23:06,990 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:23:40,976 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:24:25,492 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:25:07,219 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:25:40,869 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:26:23,688 - Quant - INFO - Started Optimizing weight rounding of module: fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [36:38<00:00, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:26:58,635 - Quant - INFO - Deleting model inputs from location: /tmp/adaround/\n",
      "2023-01-26 19:26:58,776 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "dummy_input = torch.rand(1, 3, 224, 224)  \n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                    path=adaround_path, \n",
    "                                    filename_prefix='adaround', \n",
    "                                    default_param_bw=bits,\n",
    "                                    default_quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1744d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:26:59,150 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-26 19:26:59,167 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-26 19:26:59,167 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-26 19:26:59,168 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-26 19:26:59,174 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-26 19:26:59,175 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-26 19:26:59,175 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-26 19:26:59,175 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-26 19:26:59,176 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-26 19:26:59,176 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-26 19:26:59,177 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-26 19:26:59,177 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-26 19:26:59,177 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-26 19:26:59,178 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-26 19:26:59,178 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-26 19:26:59,178 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-26 19:26:59,179 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-26 19:26:59,179 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-26 19:26:59,179 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-26 19:26:59,180 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-26 19:26:59,180 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-26 19:26:59,181 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-26 19:26:59,181 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-26 19:26:59,181 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-26 19:26:59,182 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-26 19:26:59,182 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-26 19:26:59,182 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-26 19:26:59,183 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-26 19:26:59,183 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-26 19:26:59,183 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-26 19:26:59,184 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-26 19:26:59,184 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-26 19:26:59,184 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-26 19:26:59,185 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-26 19:26:59,185 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-26 19:26:59,186 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-26 19:26:59,186 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-26 19:26:59,186 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=ada_model,\n",
    "#                            quant_scheme=QuantScheme.post_training_tf,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5319be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 19:26:59,203 - Quant - INFO - Setting quantization encodings for parameter: conv1.weight\n",
      "2023-01-26 19:26:59,203 - Quant - INFO - Freezing quantization encodings for parameter: conv1.weight\n",
      "2023-01-26 19:26:59,204 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,204 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,205 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,205 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,205 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,206 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,206 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,206 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,207 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,207 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,207 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,208 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,208 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,209 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,209 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,209 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,210 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,210 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,210 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,211 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,211 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,211 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,212 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,212 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,212 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,213 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,213 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,214 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,214 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,214 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,215 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,215 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,215 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,216 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,216 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,216 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,217 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,217 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,218 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,218 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,218 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,219 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,219 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,219 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,220 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,220 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,220 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,221 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,221 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,221 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,222 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,222 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,223 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,223 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,223 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,224 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,224 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,225 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,225 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,225 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,226 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,226 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,226 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,227 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,227 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,227 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,228 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,228 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,228 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,229 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,229 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,230 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,230 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,230 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,231 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,231 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,231 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,232 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,232 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,232 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,233 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,233 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,234 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,234 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,234 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,235 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,235 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,235 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,236 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,236 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2023-01-26 19:26:59,236 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,237 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv1.weight\n",
      "2023-01-26 19:26:59,237 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,237 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv2.weight\n",
      "2023-01-26 19:26:59,238 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,238 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv3.weight\n",
      "2023-01-26 19:26:59,239 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,239 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv1.weight\n",
      "2023-01-26 19:26:59,239 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,241 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv2.weight\n",
      "2023-01-26 19:26:59,241 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,241 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv3.weight\n",
      "2023-01-26 19:26:59,242 - Quant - INFO - Setting quantization encodings for parameter: fc.weight\n",
      "2023-01-26 19:26:59,242 - Quant - INFO - Freezing quantization encodings for parameter: fc.weight\n"
     ]
    }
   ],
   "source": [
    "sim.set_and_freeze_param_encodings(encoding_path=os.path.join(adaround_path, 'adaround.encodings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c433673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=partial(pass_calibration_data, dataloader=train_loader),\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c46c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [01:44<00:00, 15.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6070342509603073"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf_enhanced\n",
    "accuracy(sim.model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c924f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
