{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5abc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085ed3b4-eb16-4799-bef8-6097ced96443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78892c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:10:28,172 - root - INFO - AIMET\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "\n",
    "from source.data import get_imagenet_test_loader, get_imagenet_train_val_loaders\n",
    "from source.eval import accuracy\n",
    "from source.admm import build_cp_layer\n",
    "from source.utils import bncalibrate_model\n",
    "from source.rank_map import get_rank_map\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fe815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, use_cuda):\n",
    "    batch_size = train_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in train_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            print(batch_cntr * batch_size)\n",
    "            if (batch_cntr * batch_size) >= samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701597d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bdd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5282a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'admm'\n",
    "qscheme = 'tensor_affine'\n",
    "bits = 8\n",
    "eps = 0.003\n",
    "decomp = 'cp3'\n",
    "rank_map = get_rank_map(eps, decomp)\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b8c88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model e=0.003_d=cp3_affine.calibrated_10000\n"
     ]
    }
   ],
   "source": [
    "# model = resnet18(pretrained=True).to(device)\n",
    "print(f\"loading model e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\")\n",
    "model = torch.load(f\"e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\")\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e628c071-6cbd-4023-bb5a-f65722ca48de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553766100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "orig_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    orig_macs += x[0]\n",
    "orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f8e33a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(lidx)\n\u001b[1;32m     10\u001b[0m layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(lname)[lidx]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(ltype)\n\u001b[0;32m---> 11\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mkernel_size\n\u001b[1;32m     12\u001b[0m stride \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     13\u001b[0m padding \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mpadding\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'kernel_size'"
     ]
    }
   ],
   "source": [
    "for module in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "    for layer_path in [f'{module}.0.conv1', f'{module}.0.conv2', \n",
    "#                        f'{module}.0.downsample',\n",
    "                       f'{module}.1.conv1', f'{module}.1.conv2']:\n",
    "        # there is no layer1.0.downsample layer\n",
    "        if layer_path == 'layer1.0.downsample': continue\n",
    "            \n",
    "        lname, lidx, ltype = layer_path.split('.')\n",
    "        lidx = int(lidx)\n",
    "        layer = model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "        kernel_size = layer.kernel_size\n",
    "        stride = layer.stride\n",
    "        padding = layer.padding\n",
    "        cin = layer.in_channels\n",
    "        cout = layer.out_channels\n",
    "        rank = rank_map[layer_path]\n",
    "        bias = layer.bias\n",
    "        if bias is not None: bias = bias.detach()\n",
    "        \n",
    "        print(f'loading {bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}')\n",
    "        A = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_0.pt').to(device)\n",
    "        assert A.dtype == torch.float \n",
    "        B = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_1.pt').to(device)\n",
    "        C = torch.load(f'../{bits}bit_{qscheme}/factors_{method}_seed{seed}/{layer_path}_{method}_random_rank_{rank}_mode_2.pt').to(device)\n",
    "\n",
    "        model.__getattr__(lname)[lidx].__setattr__(\n",
    "            ltype, build_cp_layer(rank, [A,B,C], bias, cin, cout, kernel_size, padding, stride).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5969e1a-1779-43ab-9cb0-25945ff90c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39531666421972406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "redc_macs = 0\n",
    "for x in model_stats.macs.values():\n",
    "    redc_macs += x[0]\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6dcc0bd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:48<00:00,  1.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42276"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced9c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2459 [01:51<3:34:47,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10000\n",
    "model = bncalibrate_model(model, train_loader, num_samples=num_samples, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd2a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59094"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d27effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da0938",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7184655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 17:54:15,004 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2023-01-16 17:54:15,005 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2023-01-16 17:54:15,006 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2023-01-16 17:54:15,008 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2023-01-16 17:54:15,008 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2023-01-16 17:54:15,009 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2023-01-16 17:54:15,010 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2023-01-16 17:54:15,010 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2023-01-16 17:54:15,011 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2023-01-16 17:54:15,011 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2023-01-16 17:54:15,012 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2023-01-16 17:54:15,012 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2023-01-16 17:54:15,013 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2023-01-16 17:54:15,013 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2023-01-16 17:54:15,014 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2023-01-16 17:54:15,014 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4f31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 17:54:15,409 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2023-01-16 17:54:15,410 - Utils - INFO - ...... subset to store [Conv_6, BatchNormalization_7]\n",
      "2023-01-16 17:54:15,411 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2023-01-16 17:54:15,411 - Utils - INFO - ...... subset to store [Conv_17, BatchNormalization_18]\n",
      "2023-01-16 17:54:15,411 - Utils - INFO - ...... subset to store [Conv_22, BatchNormalization_23]\n",
      "2023-01-16 17:54:15,412 - Utils - INFO - ...... subset to store [Conv_28, BatchNormalization_29]\n",
      "2023-01-16 17:54:15,412 - Utils - INFO - ...... subset to store [Conv_33, BatchNormalization_34]\n",
      "2023-01-16 17:54:15,413 - Utils - INFO - ...... subset to store [Conv_41, BatchNormalization_42]\n",
      "2023-01-16 17:54:15,413 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2023-01-16 17:54:15,413 - Utils - INFO - ...... subset to store [Conv_52, BatchNormalization_53]\n",
      "2023-01-16 17:54:15,414 - Utils - INFO - ...... subset to store [Conv_57, BatchNormalization_58]\n",
      "2023-01-16 17:54:15,414 - Utils - INFO - ...... subset to store [Conv_65, BatchNormalization_66]\n",
      "2023-01-16 17:54:15,415 - Utils - INFO - ...... subset to store [Conv_70, BatchNormalization_71]\n",
      "2023-01-16 17:54:15,416 - Utils - INFO - ...... subset to store [Conv_76, BatchNormalization_77]\n",
      "2023-01-16 17:54:15,416 - Utils - INFO - ...... subset to store [Conv_81, BatchNormalization_82]\n",
      "2023-01-16 17:54:15,416 - Utils - INFO - ...... subset to store [Conv_89, BatchNormalization_90]\n",
      "2023-01-16 17:54:15,417 - Utils - INFO - ...... subset to store [Conv_94, BatchNormalization_95]\n",
      "2023-01-16 17:54:15,417 - Utils - INFO - ...... subset to store [Conv_83, BatchNormalization_84]\n",
      "2023-01-16 17:54:15,418 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2023-01-16 17:54:15,418 - Utils - INFO - ...... subset to store [Conv_35, BatchNormalization_36]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20191c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 17:54:16,355 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-16 17:54:16,374 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-16 17:54:16,375 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-16 17:54:16,375 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-16 17:54:16,382 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 17:54:16,382 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 17:54:16,383 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 17:54:16,383 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 17:54:16,384 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 17:54:16,384 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 17:54:16,385 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 17:54:16,385 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 17:54:16,385 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 17:54:16,386 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 17:54:16,386 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 17:54:16,387 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 17:54:16,387 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 17:54:16,388 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 17:54:16,388 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 17:54:16,389 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 17:54:16,389 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 17:54:16,390 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 17:54:16,390 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 17:54:16,390 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 17:54:16,391 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 17:54:16,391 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 17:54:16,392 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 17:54:16,392 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 17:54:16,392 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 17:54:16,393 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 17:54:16,393 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 17:54:16,394 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 17:54:16,394 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 17:54:16,395 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 17:54:16,395 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 17:54:16,395 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 17:54:16,396 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-16 17:54:16,396 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "#                            quant_scheme=QuantScheme.post_training_tf,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ef22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e356f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:56<00:00,  1.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44936"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post_training_tf_enchanced\n",
    "accuracy(sim.model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab736fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4189"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post_training_tf\n",
    "accuracy(sim.model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395feece",
   "metadata": {},
   "source": [
    "# AdaRound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b523d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:10:51,197 - Quant - INFO - Functional         : Adding new module for node: {add} \n",
      "2023-01-16 18:10:51,198 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_0_relu_1} \n",
      "2023-01-16 18:10:51,199 - Quant - INFO - Functional         : Adding new module for node: {add_1} \n",
      "2023-01-16 18:10:51,199 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer1_1_relu_1} \n",
      "2023-01-16 18:10:51,200 - Quant - INFO - Functional         : Adding new module for node: {add_2} \n",
      "2023-01-16 18:10:51,201 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_0_relu_1} \n",
      "2023-01-16 18:10:51,201 - Quant - INFO - Functional         : Adding new module for node: {add_3} \n",
      "2023-01-16 18:10:51,202 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer2_1_relu_1} \n",
      "2023-01-16 18:10:51,202 - Quant - INFO - Functional         : Adding new module for node: {add_4} \n",
      "2023-01-16 18:10:51,203 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_0_relu_1} \n",
      "2023-01-16 18:10:51,203 - Quant - INFO - Functional         : Adding new module for node: {add_5} \n",
      "2023-01-16 18:10:51,204 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer3_1_relu_1} \n",
      "2023-01-16 18:10:51,204 - Quant - INFO - Functional         : Adding new module for node: {add_6} \n",
      "2023-01-16 18:10:51,205 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_0_relu_1} \n",
      "2023-01-16 18:10:51,205 - Quant - INFO - Functional         : Adding new module for node: {add_7} \n",
      "2023-01-16 18:10:51,206 - Quant - INFO - Reused/Duplicate   : Adding new module for node: {layer4_1_relu_1} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/fx/graph.py:606: UserWarning: Attempted to insert a call_module Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule\n",
      "  warnings.warn(\"Attempted to insert a call_module Node with \"\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5fe6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:10:51,900 - Utils - INFO - ...... subset to store [Conv_0, BatchNormalization_1]\n",
      "2023-01-16 18:10:51,901 - Utils - INFO - ...... subset to store [Conv_6, BatchNormalization_7]\n",
      "2023-01-16 18:10:51,901 - Utils - INFO - ...... subset to store [Conv_11, BatchNormalization_12]\n",
      "2023-01-16 18:10:51,902 - Utils - INFO - ...... subset to store [Conv_17, BatchNormalization_18]\n",
      "2023-01-16 18:10:51,902 - Utils - INFO - ...... subset to store [Conv_22, BatchNormalization_23]\n",
      "2023-01-16 18:10:51,902 - Utils - INFO - ...... subset to store [Conv_28, BatchNormalization_29]\n",
      "2023-01-16 18:10:51,903 - Utils - INFO - ...... subset to store [Conv_33, BatchNormalization_34]\n",
      "2023-01-16 18:10:51,904 - Utils - INFO - ...... subset to store [Conv_41, BatchNormalization_42]\n",
      "2023-01-16 18:10:51,904 - Utils - INFO - ...... subset to store [Conv_46, BatchNormalization_47]\n",
      "2023-01-16 18:10:51,904 - Utils - INFO - ...... subset to store [Conv_52, BatchNormalization_53]\n",
      "2023-01-16 18:10:51,905 - Utils - INFO - ...... subset to store [Conv_57, BatchNormalization_58]\n",
      "2023-01-16 18:10:51,905 - Utils - INFO - ...... subset to store [Conv_65, BatchNormalization_66]\n",
      "2023-01-16 18:10:51,906 - Utils - INFO - ...... subset to store [Conv_70, BatchNormalization_71]\n",
      "2023-01-16 18:10:51,906 - Utils - INFO - ...... subset to store [Conv_76, BatchNormalization_77]\n",
      "2023-01-16 18:10:51,906 - Utils - INFO - ...... subset to store [Conv_81, BatchNormalization_82]\n",
      "2023-01-16 18:10:51,907 - Utils - INFO - ...... subset to store [Conv_89, BatchNormalization_90]\n",
      "2023-01-16 18:10:51,907 - Utils - INFO - ...... subset to store [Conv_94, BatchNormalization_95]\n",
      "2023-01-16 18:10:51,908 - Utils - INFO - ...... subset to store [Conv_83, BatchNormalization_84]\n",
      "2023-01-16 18:10:51,908 - Utils - INFO - ...... subset to store [Conv_59, BatchNormalization_60]\n",
      "2023-01-16 18:10:51,908 - Utils - INFO - ...... subset to store [Conv_35, BatchNormalization_36]\n"
     ]
    }
   ],
   "source": [
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b870d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = AdaroundParameters(data_loader=val_loader, num_batches=2000//val_loader.batch_size, default_num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbc5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224).cuda()\n",
    "# adaround_path = f\"adaround_e={eps}_d={decomp}_{qscheme.split('_')[-1]}.calibrated_{num_samples}\"\n",
    "adaround_path = 'adaround'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f70370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(adaround_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db1e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n",
      "2023-01-16 18:10:56,731 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-16 18:10:56,750 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-16 18:10:56,750 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-16 18:10:56,751 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-16 18:10:56,757 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 18:10:56,758 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 18:10:56,758 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 18:10:56,759 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 18:10:56,759 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 18:10:56,759 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 18:10:56,760 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 18:10:56,760 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 18:10:56,761 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 18:10:56,761 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 18:10:56,761 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 18:10:56,762 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 18:10:56,763 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 18:10:56,764 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 18:10:56,764 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 18:10:56,765 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 18:10:56,765 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 18:10:56,765 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 18:10:56,766 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 18:10:56,766 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 18:10:56,766 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 18:10:56,767 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 18:10:56,767 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 18:10:56,767 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 18:10:56,768 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 18:10:56,768 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 18:10:56,769 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 18:10:56,769 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 18:10:56,769 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 18:10:56,770 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 18:10:56,770 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 18:10:56,770 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 18:10:56,771 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-16 18:10:56,771 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-16 18:11:03,585 - Utils - INFO - Caching 4 batches from data loader at path location: /tmp/adaround/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:11:05,909 - Quant - INFO - Started Optimizing weight rounding of module: conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:12:10,295 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:12:37,977 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:13:04,232 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:13:32,254 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:13:58,904 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:14:24,796 - Quant - INFO - Started Optimizing weight rounding of module: layer1.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:14:52,068 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:15:20,704 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:15:49,537 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:16:19,676 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:16:47,791 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:17:16,134 - Quant - INFO - Started Optimizing weight rounding of module: layer1.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:17:45,068 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:18:18,246 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:18:48,084 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:19:13,331 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:19:41,688 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:20:05,551 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:20:30,424 - Quant - INFO - Started Optimizing weight rounding of module: layer2.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:20:57,099 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:21:24,321 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:21:48,857 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:22:15,081 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:22:42,216 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:23:06,089 - Quant - INFO - Started Optimizing weight rounding of module: layer2.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:23:31,174 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:23:58,538 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:24:21,650 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:24:44,827 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:25:07,896 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:25:29,745 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:25:52,883 - Quant - INFO - Started Optimizing weight rounding of module: layer3.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:26:19,376 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:26:42,383 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:27:04,563 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:27:28,436 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:27:51,690 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:28:13,858 - Quant - INFO - Started Optimizing weight rounding of module: layer3.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:28:37,070 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:29:00,360 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:29:22,426 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:29:48,297 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:30:14,095 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:30:35,887 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:31:01,361 - Quant - INFO - Started Optimizing weight rounding of module: layer4.0.downsample.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:31:24,481 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:31:50,282 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:32:11,926 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv1.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:32:38,449 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:33:03,107 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:33:24,214 - Quant - INFO - Started Optimizing weight rounding of module: layer4.1.conv2.conv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:33:46,612 - Quant - INFO - Started Optimizing weight rounding of module: fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [23:01<00:00, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:34:07,795 - Quant - INFO - Deleting model inputs from location: /tmp/adaround/\n",
      "2023-01-16 18:34:07,905 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "dummy_input = torch.rand(1, 3, 224, 224)  \n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                    path=adaround_path, \n",
    "                                    filename_prefix='adaround', \n",
    "                                    default_param_bw=8,\n",
    "                                    default_quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1744d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:40:17,727 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.8/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2023-01-16 18:40:17,745 - Quant - INFO - Unsupported op type Squeeze\n",
      "2023-01-16 18:40:17,746 - Quant - INFO - Unsupported op type Pad\n",
      "2023-01-16 18:40:17,746 - Quant - INFO - Unsupported op type Mean\n",
      "2023-01-16 18:40:17,753 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 18:40:17,753 - Utils - INFO - ...... subset to store [Conv_0, Relu_1]\n",
      "2023-01-16 18:40:17,754 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 18:40:17,754 - Utils - INFO - ...... subset to store [Conv_5, Relu_6]\n",
      "2023-01-16 18:40:17,755 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 18:40:17,755 - Utils - INFO - ...... subset to store [Add_10, Relu_11]\n",
      "2023-01-16 18:40:17,756 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 18:40:17,756 - Utils - INFO - ...... subset to store [Conv_14, Relu_15]\n",
      "2023-01-16 18:40:17,757 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 18:40:17,757 - Utils - INFO - ...... subset to store [Add_19, Relu_20]\n",
      "2023-01-16 18:40:17,757 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 18:40:17,758 - Utils - INFO - ...... subset to store [Conv_23, Relu_24]\n",
      "2023-01-16 18:40:17,758 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 18:40:17,758 - Utils - INFO - ...... subset to store [Add_29, Relu_30]\n",
      "2023-01-16 18:40:17,759 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 18:40:17,759 - Utils - INFO - ...... subset to store [Conv_33, Relu_34]\n",
      "2023-01-16 18:40:17,760 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 18:40:17,760 - Utils - INFO - ...... subset to store [Add_38, Relu_39]\n",
      "2023-01-16 18:40:17,760 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 18:40:17,761 - Utils - INFO - ...... subset to store [Conv_42, Relu_43]\n",
      "2023-01-16 18:40:17,761 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 18:40:17,761 - Utils - INFO - ...... subset to store [Add_48, Relu_49]\n",
      "2023-01-16 18:40:17,762 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 18:40:17,762 - Utils - INFO - ...... subset to store [Conv_52, Relu_53]\n",
      "2023-01-16 18:40:17,763 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 18:40:17,763 - Utils - INFO - ...... subset to store [Add_57, Relu_58]\n",
      "2023-01-16 18:40:17,763 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 18:40:17,764 - Utils - INFO - ...... subset to store [Conv_61, Relu_62]\n",
      "2023-01-16 18:40:17,764 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 18:40:17,765 - Utils - INFO - ...... subset to store [Add_67, Relu_68]\n",
      "2023-01-16 18:40:17,765 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 18:40:17,765 - Utils - INFO - ...... subset to store [Conv_71, Relu_72]\n",
      "2023-01-16 18:40:17,766 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n",
      "2023-01-16 18:40:17,766 - Utils - INFO - ...... subset to store [Add_76, Relu_77]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)    \n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=ada_model,\n",
    "#                            quant_scheme=QuantScheme.post_training_tf,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5319be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:40:21,479 - Quant - INFO - Setting quantization encodings for parameter: conv1.weight\n",
      "2023-01-16 18:40:21,479 - Quant - INFO - Freezing quantization encodings for parameter: conv1.weight\n",
      "2023-01-16 18:40:21,480 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,480 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,481 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,481 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,481 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,482 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,482 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,483 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,483 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,484 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,485 - Quant - INFO - Setting quantization encodings for parameter: layer1.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,485 - Quant - INFO - Freezing quantization encodings for parameter: layer1.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,486 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,486 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,486 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,487 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,487 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,487 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,488 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,488 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,489 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,489 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,489 - Quant - INFO - Setting quantization encodings for parameter: layer1.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,490 - Quant - INFO - Freezing quantization encodings for parameter: layer1.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,490 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,491 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,491 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,491 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,492 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,492 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,492 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,493 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,493 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,493 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,494 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,494 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,495 - Quant - INFO - Setting quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,495 - Quant - INFO - Freezing quantization encodings for parameter: layer2.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,495 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,496 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,496 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,497 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,497 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,497 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,498 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,498 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,499 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,499 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,500 - Quant - INFO - Setting quantization encodings for parameter: layer2.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,500 - Quant - INFO - Freezing quantization encodings for parameter: layer2.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,504 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,504 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,505 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,506 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,506 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,506 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,507 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,507 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,508 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,508 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,508 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,509 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,509 - Quant - INFO - Setting quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,510 - Quant - INFO - Freezing quantization encodings for parameter: layer3.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,510 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,511 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,511 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,511 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,512 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,512 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv1.conv3.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:40:21,513 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,513 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,515 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,516 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,516 - Quant - INFO - Setting quantization encodings for parameter: layer3.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,517 - Quant - INFO - Freezing quantization encodings for parameter: layer3.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,518 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,518 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,519 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,519 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,520 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,521 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,521 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,522 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,522 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,523 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,523 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,524 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,524 - Quant - INFO - Setting quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,525 - Quant - INFO - Freezing quantization encodings for parameter: layer4.0.downsample.0.weight\n",
      "2023-01-16 18:40:21,525 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,526 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv1.weight\n",
      "2023-01-16 18:40:21,526 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,526 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv2.weight\n",
      "2023-01-16 18:40:21,527 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,527 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv1.conv3.weight\n",
      "2023-01-16 18:40:21,528 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,528 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv1.weight\n",
      "2023-01-16 18:40:21,529 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,529 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv2.weight\n",
      "2023-01-16 18:40:21,530 - Quant - INFO - Setting quantization encodings for parameter: layer4.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,530 - Quant - INFO - Freezing quantization encodings for parameter: layer4.1.conv2.conv3.weight\n",
      "2023-01-16 18:40:21,530 - Quant - INFO - Setting quantization encodings for parameter: fc.weight\n",
      "2023-01-16 18:40:21,531 - Quant - INFO - Freezing quantization encodings for parameter: fc.weight\n"
     ]
    }
   ],
   "source": [
    "sim.set_and_freeze_param_encodings(encoding_path=os.path.join(adaround_path, 'adaround.encodings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c433673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c46c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:55<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59534"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf_enchanced\n",
    "accuracy(sim.model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "884be9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf\n",
    "accuracy(sim.model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885bba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
