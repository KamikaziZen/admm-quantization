{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4f3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe59c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from flopco import FlopCo\n",
    "from musco.pytorch.compressor.config_gen import generate_model_compr_kwargs\n",
    "from musco.pytorch import Compressor\n",
    "from musco.pytorch.compressor.rank_estimation.estimator import estimate_rank_for_compression_rate\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from source.data import get_imagenet_train_val_loaders, get_imagenet_test_loader\n",
    "from source.eval import accuracy, estimate_macs\n",
    "from source.utils import get_layer_by_name, batchnorm_callibration\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a3d56c-8774-4cd8-928f-5960da007d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rank_for_layer(model, lname, decomposition, train_loader, val_loader, \n",
    "                             eval_func, bn_cal_func, bn_cal_n_iters, score_eps, \n",
    "                             max_rank, min_rank=3, grid_step=1, nx=1, device='cuda'):\n",
    "    '''\n",
    "    Find minimal decomposition rank for given acceptable target metric drop (uses binary search)\n",
    "    Parameters:\n",
    "    model           -   Initial model\n",
    "    lname           -   Name of layer to find decomposition rank, String\n",
    "    decomposition   -   Decomposition algorithm name, Options: (cp3, tucker2, svd), String\n",
    "    score_eps       -   Acceptable target metric drop, float\n",
    "    train_loader    -   Training dataset dataloader, Pytorch Dataloader\n",
    "    val_loader      -   Validation dataset dataloader, Pytorch Dataloader\n",
    "    eval_func       -   Function for model evaluation (returns target metric score,\n",
    "                        args: temp_model, val_loader, device), Python function\n",
    "    bn_cal_func     -   Function for batchnorm statistics calibration\n",
    "                        (args: emp_model, train_loader, lname, bn_cal_n_iters, device), Python function\n",
    "    bn_cal_n_iters  -   Number of batchnorm callibration iterations, int\n",
    "    max_rank        -   Upper bound of rank search, int\n",
    "    min_rank        -   Lower bound of rank search, int\n",
    "    grid_step       -   Rank search grid step (search for ranks multiple of grid_step)\n",
    "    nx              -   Minimal compression ratio for layer FLOPs, float\n",
    "    device          -   Device to store the model\n",
    "    \n",
    "    Output:\n",
    "    best_rank       -   Best rank for compression of given layer, int or None\n",
    "                        (if layer can not be compressed with given settings)\n",
    "    '''\n",
    "    \n",
    "    if decomposition not in ['cp3', 'tucker2', 'svd', 'cp3-epc']:\n",
    "        raise ValueError('Wrong decomposition name. Correct options: (cp3, tucker2, svd, cp3-epc)')\n",
    "    \n",
    "    curr_rank = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_max = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_min = min_rank // grid_step if min_rank // grid_step != 0 else 1\n",
    "    best_rank = None\n",
    "\n",
    "    n = int(np.log2(curr_max)) + 1\n",
    "    score_init = eval_func(model.to(device), val_loader, device=device)\n",
    "    \n",
    "    init_layer = get_layer_by_name(model, lname)\n",
    "    ch_ratio = init_layer.in_channels / init_layer.out_channels\n",
    "    \n",
    "    if curr_max < curr_min:\n",
    "        print(\"Layer can not be compressed with given grid step\")\n",
    "\n",
    "    for i in range(n):\n",
    "        print(\"Search iter {}: ranks (min, curr, max): ({}, {}, {})\".format(i, curr_min, curr_rank, \n",
    "                                                                            curr_max))\n",
    "\n",
    "        print(\"-------------------------\\n Compression step\")\n",
    "        \n",
    "        manual_rank = (int(curr_rank * ch_ratio), curr_rank) if decomposition=='tucker2' else curr_rank\n",
    "        \n",
    "        model_compr_kwargs = {lname: {'decomposition': decomposition,\n",
    "                                      'rank_selection': 'manual',\n",
    "                                      'manual_rank': [manual_rank],\n",
    "                                      'curr_compr_iter': 0}\n",
    "                              }\n",
    "        model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "\n",
    "        compressor = Compressor(copy.deepcopy(model.cpu()),\n",
    "                                model_stats,\n",
    "                                ft_every=3,\n",
    "                                nglobal_compress_iters=1,\n",
    "                                model_compr_kwargs = model_compr_kwargs,\n",
    "                               )\n",
    "        compressor.compression_step()\n",
    "\n",
    "        print(\"-------------------------\\n Calibration step\")\n",
    "        # calibrate batch norm statistics\n",
    "\n",
    "        compressor.compressed_model.to(device)\n",
    "        bn_cal_func(compressor.compressed_model, train_loader, layer_name=lname,\n",
    "                    n_batches=bn_cal_n_iters, device=device)\n",
    "\n",
    "        print(\"-------------------------\\n Test step\")\n",
    "\n",
    "        # eval model\n",
    "        score = eval_func(compressor.compressed_model, val_loader, device=device)\n",
    "        print('Current score: {}'.format(score))\n",
    "\n",
    "        # clear memory\n",
    "        del compressor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if score + score_eps < score_init:\n",
    "\n",
    "            if i == 0:\n",
    "                print(\"Bad layer to compress\")\n",
    "                if nx > 1:\n",
    "                    best_rank = curr_rank\n",
    "                break\n",
    "            else:\n",
    "                curr_min = curr_rank\n",
    "                curr_rank = curr_rank + (curr_max - curr_rank) // 2\n",
    "        else:\n",
    "            best_rank = curr_rank\n",
    "\n",
    "            curr_max = curr_rank\n",
    "            curr_rank = curr_rank - (curr_rank - curr_min) // 2\n",
    "\n",
    "    if best_rank is not None:\n",
    "        return best_rank * grid_step\n",
    "    else:\n",
    "        return best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaff546-d25f-4b75-a8fd-ebdef06f6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3caff0-2cc2-4d0a-878c-b0df2e8a38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_macs(model, layer_name, rank):\n",
    "#     \"\"\"Returns original and reduced macs based on reduction rank\n",
    "#     original macs = C_i * W_k * H_k * C_o * W_o * H_o\n",
    "#     reduced macs = rank * C_i * W_i * H_i + rank**2 * W_k * H_k * W_o * H_o + rank * C_o * W_o * H_o\n",
    "#     where:\n",
    "#         C_i - number of input channels\n",
    "#         C_o - number of output channels\n",
    "#         W_o - width of the output image\n",
    "#         H_o - height of the output image\n",
    "#         W_i - width of the input image\n",
    "#         H_i - height of the input image\n",
    "#         W_k - width of the kernel\n",
    "#         H_k - height of the kernel\n",
    "#     \"\"\"\n",
    "#     input_shape = output_shape = (1, 3, 224, 224)\n",
    "#     layer = None\n",
    "#     x = torch.rand(*input_shape)\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for lname, layer in model.named_modules():\n",
    "#             if not (isinstance(layer, nn.Conv2d) \n",
    "#                     or isinstance(layer, nn.BatchNorm2d) \n",
    "#                     or isinstance(layer, nn.MaxPool2d) \n",
    "#                     or isinstance(layer, nn.ReLU)): continue\n",
    "#             input_shape = x.shape\n",
    "#             x = layer(x)\n",
    "#             output_shape = x.shape\n",
    "#             if lname == layer_name: break\n",
    "                \n",
    "#     if not isinstance(layer, nn.Conv2d):\n",
    "#         raise NotImplementedError('Function estimate_macs works only for Conv2d layers')\n",
    "        \n",
    "#     orig_macs = layer.in_channels * layer.kernel_size[-1] * layer.kernel_size[-2] \\\n",
    "#                 * layer.out_channels * output_shape[-1] * output_shape[-2]\n",
    "#     redc_macs = rank * layer.in_channels * input_shape[-1] * input_shape[-2] \\\n",
    "#                 + rank**2 * layer.kernel_size[-1] * layer.kernel_size[-2] * output_shape[-1] * output_shape[-2] \\\n",
    "#                 + rank * layer.out_channels * output_shape[-1] * output_shape[-2]\n",
    "    \n",
    "#     return orig_macs, redc_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bea15a-d330-4459-8fe7-21dd1e3a5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb72086-dd36-4a29-90e4-660e4dad6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061221b7-c554-471f-9155-8650290fe324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47786c80-2768-4968-811a-25881075aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15afa518e47476db28a51c8648479a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48e241b-b0b0-47e0-8a57-c870f0d6fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = FlopCo(model, img_size=(1, 3, 224, 224), device=device)\n",
    "all_lnames = list(model_stats.flops.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80251c0-1eb1-4fe2-b716-733b3d0af537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of layer names to be compressed\n",
    "lnames_to_compress = [k for k in all_lnames if model_stats.ltypes[k]['type'] == nn.Conv2d \\\n",
    "                      and k != 'conv1' and 'downsample' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42b41c9-32d2-4c05-b69b-b328d2a0d466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layer1.0.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "Shape: torch.Size([128, 64, 3, 3])\n",
      "Rank: 91\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "Shape: torch.Size([256, 128, 3, 3])\n",
      "Rank: 187\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "Shape: torch.Size([512, 256, 3, 3])\n",
      "Rank: 379\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_ranks = {}\n",
    "\n",
    "for lname in lnames_to_compress:\n",
    "    layer_shape = get_layer_by_name(model, lname).weight.shape\n",
    "    print('Layer:', lname)\n",
    "    print('Shape:', layer_shape)\n",
    "    rank = estimate_rank_for_compression_rate(layer_shape, rate=4,\n",
    "                                              tensor_format='cp3')\n",
    "    print('Rank:', rank)\n",
    "    print()\n",
    "    max_ranks[lname] = rank\n",
    "    \n",
    "saved_ranks = {k: None for k in all_lnames}\n",
    "min_ranks = {k: 10 for k in max_ranks.keys()}\n",
    "curr_ranks = copy.deepcopy(max_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0fef51-5a94-47b1-9987-e3f1e941ec2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:40<00:00,  1.01it/s]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search iter 0: ranks (min, curr, max): (10, 67, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [67], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:43<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7831372549019607\n",
      "Bad layer to compress\n",
      "CPU times: user 2min 49s, sys: 11.8 s, total: 3min 1s\n",
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "find_best_rank_for_layer(model, \n",
    "                         lname='layer1.0.conv1', \n",
    "                         decomposition='cp3-epc', \n",
    "                         train_loader=train_loader, \n",
    "                         val_loader=val_loader, \n",
    "                         eval_func=accuracy,\n",
    "                         bn_cal_func=batchnorm_callibration, \n",
    "                         bn_cal_n_iters=1, \n",
    "                         score_eps=0.01,\n",
    "                         max_rank=max_ranks['layer1.0.conv1'], \n",
    "                         min_rank=min_ranks['layer1.0.conv1'],\n",
    "                         grid_step=1, \n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7bf644b-f110-4fa5-82dc-cdb3eaa6660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0872395833333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer1.0.conv1', 60)\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114452bf-4852-48cb-a704-1aafe6a579f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0143229166666665"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer1.0.conv1', 84)\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c32a8d-06d8-443b-b72e-7ea555bf3dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:40<00:00,  1.02it/s]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search iter 0: ranks (min, curr, max): (10, 570, 570)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer4.1.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [570], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:41<00:00,  1.00it/s]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7935882352941176\n",
      "Search iter 1: ranks (min, curr, max): (10, 290, 570)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer4.1.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [290], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:40<00:00,  1.02it/s]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7914901960784314\n",
      "Search iter 2: ranks (min, curr, max): (10, 150, 290)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer4.1.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [150], 'curr_compr_iter': 0}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lname = 'layer4.1.conv2'\n",
    "find_best_rank_for_layer(model, \n",
    "                         lname=lname, \n",
    "                         decomposition='cp3', \n",
    "                         train_loader=train_loader, \n",
    "                         val_loader=val_loader, \n",
    "                         eval_func=accuracy,\n",
    "                         bn_cal_func=batchnorm_callibration, \n",
    "                         bn_cal_n_iters=1, \n",
    "                         score_eps=0.005,\n",
    "                         max_rank=max_ranks[lname], \n",
    "                         min_rank=min_ranks[lname],\n",
    "                         grid_step=1, \n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8693c-4cba-45e2-a9c5-612eedb540e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer4.1.conv2', 65)\n",
    "redc_macs / orig_macs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark20",
   "language": "python",
   "name": "mark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
