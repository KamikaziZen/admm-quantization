{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4f3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe59c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from flopco import FlopCo\n",
    "from musco.pytorch.compressor.config_gen import generate_model_compr_kwargs\n",
    "from musco.pytorch import Compressor\n",
    "from musco.pytorch.compressor.rank_estimation.estimator import estimate_rank_for_compression_rate\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from source.data import get_imagenet_train_val_loaders, get_imagenet_test_loader\n",
    "from source.eval import accuracy, estimate_macs\n",
    "from source.utils import get_layer_by_name, bncalibrate_layer\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a3d56c-8774-4cd8-928f-5960da007d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rank_for_layer(model, lname, decomposition, train_loader, val_loader, \n",
    "                             eval_func, bn_cal_func, bn_cal_n_iters, score_eps, \n",
    "                             max_rank, min_rank=3, grid_step=1, nx=1, device='cuda'):\n",
    "    '''\n",
    "    Find minimal decomposition rank for given acceptable target metric drop (uses binary search)\n",
    "    Parameters:\n",
    "    model           -   Initial model\n",
    "    lname           -   Name of layer to find decomposition rank, String\n",
    "    decomposition   -   Decomposition algorithm name, Options: (cp3, tucker2, svd), String\n",
    "    score_eps       -   Acceptable target metric drop, float\n",
    "    train_loader    -   Training dataset dataloader, Pytorch Dataloader\n",
    "    val_loader      -   Validation dataset dataloader, Pytorch Dataloader\n",
    "    eval_func       -   Function for model evaluation (returns target metric score,\n",
    "                        args: temp_model, val_loader, device), Python function\n",
    "    bn_cal_func     -   Function for batchnorm statistics calibration\n",
    "                        (args: emp_model, train_loader, lname, bn_cal_n_iters, device), Python function\n",
    "    bn_cal_n_iters  -   Number of batchnorm callibration iterations, int\n",
    "    max_rank        -   Upper bound of rank search, int\n",
    "    min_rank        -   Lower bound of rank search, int\n",
    "    grid_step       -   Rank search grid step (search for ranks multiple of grid_step)\n",
    "    nx              -   Minimal compression ratio for layer FLOPs, float\n",
    "    device          -   Device to store the model\n",
    "    \n",
    "    Output:\n",
    "    best_rank       -   Best rank for compression of given layer, int or None\n",
    "                        (if layer can not be compressed with given settings)\n",
    "    '''\n",
    "    \n",
    "    if decomposition not in ['cp3', 'tucker2', 'svd', 'cp3-epc']:\n",
    "        raise ValueError('Wrong decomposition name. Correct options: (cp3, tucker2, svd, cp3-epc)')\n",
    "    \n",
    "    curr_rank = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_max = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_min = min_rank // grid_step if min_rank // grid_step != 0 else 1\n",
    "    best_rank = None\n",
    "\n",
    "    n = int(np.log2(curr_max)) + 1\n",
    "    score_init = eval_func(model.to(device), val_loader, device=device)\n",
    "    \n",
    "    init_layer = get_layer_by_name(model, lname)\n",
    "    ch_ratio = init_layer.in_channels / init_layer.out_channels\n",
    "    \n",
    "    if curr_max < curr_min:\n",
    "        print(\"Layer can not be compressed with given grid step\")\n",
    "\n",
    "    for i in range(n):\n",
    "        print(\"Search iter {}: ranks (min, curr, max): ({}, {}, {})\".format(i, curr_min, curr_rank, \n",
    "                                                                            curr_max))\n",
    "\n",
    "        print(\"-------------------------\\n Compression step\")\n",
    "        \n",
    "        manual_rank = (int(curr_rank * ch_ratio), curr_rank) if decomposition=='tucker2' else curr_rank\n",
    "        \n",
    "        model_compr_kwargs = {lname: {'decomposition': decomposition,\n",
    "                                      'rank_selection': 'manual',\n",
    "                                      'manual_rank': [manual_rank],\n",
    "                                      'curr_compr_iter': 0}\n",
    "                              }\n",
    "        model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "\n",
    "        compressor = Compressor(copy.deepcopy(model.cpu()),\n",
    "                                model_stats,\n",
    "                                ft_every=3,\n",
    "                                nglobal_compress_iters=1,\n",
    "                                model_compr_kwargs = model_compr_kwargs,\n",
    "                               )\n",
    "        compressor.compression_step()\n",
    "\n",
    "        print(\"-------------------------\\n Calibration step\")\n",
    "        # calibrate batch norm statistics\n",
    "\n",
    "        compressor.compressed_model.to(device)\n",
    "        bn_cal_func(compressor.compressed_model, train_loader, layer_name=lname,\n",
    "                    n_batches=bn_cal_n_iters, device=device)\n",
    "\n",
    "        print(\"-------------------------\\n Test step\")\n",
    "\n",
    "        # eval model\n",
    "        score = eval_func(compressor.compressed_model, val_loader, device=device)\n",
    "        print('Current score: {}'.format(score))\n",
    "\n",
    "        # clear memory\n",
    "        del compressor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if score + score_eps < score_init:\n",
    "\n",
    "            if i == 0:\n",
    "                print(\"Bad layer to compress\")\n",
    "                if nx > 1:\n",
    "                    best_rank = curr_rank\n",
    "                break\n",
    "            else:\n",
    "                curr_min = curr_rank\n",
    "                curr_rank = curr_rank + (curr_max - curr_rank) // 2\n",
    "        else:\n",
    "            best_rank = curr_rank\n",
    "\n",
    "            curr_max = curr_rank\n",
    "            curr_rank = curr_rank - (curr_rank - curr_min) // 2\n",
    "\n",
    "    if best_rank is not None:\n",
    "        return best_rank * grid_step\n",
    "    else:\n",
    "        return best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bea15a-d330-4459-8fe7-21dd1e3a5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb72086-dd36-4a29-90e4-660e4dad6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061221b7-c554-471f-9155-8650290fe324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47786c80-2768-4968-811a-25881075aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time \n",
    "# accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f48e241b-b0b0-47e0-8a57-c870f0d6fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = FlopCo(model, img_size=(1, 3, 224, 224), device=device)\n",
    "all_lnames = list(model_stats.flops.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80251c0-1eb1-4fe2-b716-733b3d0af537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of layer names to be compressed\n",
    "lnames_to_compress = [k for k in all_lnames if model_stats.ltypes[k]['type'] == nn.Conv2d \\\n",
    "                      and k != 'conv1' and 'downsample' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42b41c9-32d2-4c05-b69b-b328d2a0d466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layer1.0.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 67\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "Shape: torch.Size([128, 64, 3, 3])\n",
      "Rank: 91\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 139\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "Shape: torch.Size([256, 128, 3, 3])\n",
      "Rank: 187\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 283\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "Shape: torch.Size([512, 256, 3, 3])\n",
      "Rank: 379\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_ranks = {}\n",
    "\n",
    "for lname in lnames_to_compress:\n",
    "    layer_shape = get_layer_by_name(model, lname).weight.shape\n",
    "    print('Layer:', lname)\n",
    "    print('Shape:', layer_shape)\n",
    "    rank = estimate_rank_for_compression_rate(layer_shape, rate=4,\n",
    "                                              tensor_format='cp3')\n",
    "    print('Rank:', rank)\n",
    "    print()\n",
    "    max_ranks[lname] = rank\n",
    "    \n",
    "saved_ranks = {k: None for k in all_lnames}\n",
    "min_ranks = {k: 10 for k in max_ranks.keys()}\n",
    "curr_ranks = copy.deepcopy(max_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe0fef51-5a94-47b1-9987-e3f1e941ec2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [05:13<00:00,  3.07s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search iter 0: ranks (min, curr, max): (10, 67, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [67], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:59<00:00,  1.17s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.792235294117647\n",
      "Search iter 1: ranks (min, curr, max): (10, 39, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [39], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:53<00:00,  1.11s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.784921568627451\n",
      "Search iter 2: ranks (min, curr, max): (39, 53, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [53], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:56<00:00,  1.14s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7883137254901961\n",
      "Search iter 3: ranks (min, curr, max): (53, 60, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [60], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:51<00:00,  1.09s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7895686274509804\n",
      "Search iter 4: ranks (min, curr, max): (60, 63, 67)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [63], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:05<00:00,  1.23s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7914313725490196\n",
      "Search iter 5: ranks (min, curr, max): (60, 62, 63)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [62], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:48<00:00,  1.07s/it]\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7916274509803921\n",
      "Search iter 6: ranks (min, curr, max): (60, 61, 62)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [61], 'curr_compr_iter': 0}\n",
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [01:54<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7904705882352941\n",
      "CPU times: user 4min 2s, sys: 51.8 s, total: 4min 54s\n",
      "Wall time: 23min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lname = 'layer1.0.conv2'\n",
    "best_rank = find_best_rank_for_layer(model, \n",
    "                         lname=lname, \n",
    "                         decomposition='cp3', \n",
    "                         train_loader=train_loader, \n",
    "                         val_loader=val_loader, \n",
    "                         eval_func=accuracy,\n",
    "                         bn_cal_func=bncalibrate_layer, \n",
    "                         bn_cal_n_iters=1, \n",
    "                         score_eps=0.003,\n",
    "                         max_rank=max_ranks[lname], \n",
    "                         min_rank=min_ranks[lname],\n",
    "                         grid_step=1, \n",
    "                         device=device)\n",
    "best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7bf644b-f110-4fa5-82dc-cdb3eaa6660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2304144965277778"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, lname, best_rank, device='cpu')\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c32a8d-06d8-443b-b72e-7ea555bf3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lname = 'layer4.1.conv2'\n",
    "# find_best_rank_for_layer(model, \n",
    "#                          lname=lname, \n",
    "#                          decomposition='cp3', \n",
    "#                          train_loader=train_loader, \n",
    "#                          val_loader=val_loader, \n",
    "#                          eval_func=accuracy,\n",
    "#                          bn_cal_func=batchnorm_callibration, \n",
    "#                          bn_cal_n_iters=1, \n",
    "#                          score_eps=0.005,\n",
    "#                          max_rank=max_ranks[lname], \n",
    "#                          min_rank=min_ranks[lname],\n",
    "#                          grid_step=1, \n",
    "#                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec8693c-4cba-45e2-a9c5-612eedb540e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_macs, redc_macs = estimate_macs(model, 'layer4.1.conv2', 65)\n",
    "# redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4d3fb-f76f-4487-ba59-f712333e511a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark20",
   "language": "python",
   "name": "mark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
