{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4f3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe59c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from flopco import FlopCo\n",
    "from musco.pytorch.compressor.config_gen import generate_model_compr_kwargs\n",
    "from musco.pytorch import Compressor\n",
    "from musco.pytorch.compressor.rank_estimation.estimator import estimate_rank_for_compression_rate\n",
    "\n",
    "import copy\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from source.data import get_imagenet_train_val_loaders, get_imagenet_test_loader\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f780572-90cb-4dc1-a583-0999503bdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, dataset_loader, device='cuda', num_classes=1000):\n",
    "    def one_hot(x, K):\n",
    "        return np.array(x[:, None] == np.arange(K)[None, :], dtype=int)\n",
    "    \n",
    "    # Set BN and Droupout to eval regime\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    for (x, y) in tqdm(dataset_loader):\n",
    "        x = x.to(device)\n",
    "        y = one_hot(np.array(y.numpy()), num_classes)\n",
    "        target_class = np.argmax(y, axis=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(x).cpu().detach().numpy()\n",
    "            predicted_class = np.argmax(out, axis=1)\n",
    "            total_correct += np.sum(predicted_class == target_class)\n",
    "\n",
    "    total = len(dataset_loader) * dataset_loader.batch_size\n",
    "    return total_correct / total\n",
    "\n",
    "\n",
    "def get_layer_by_name(model, mname):\n",
    "    '''\n",
    "    Extract layer using layer name\n",
    "    '''\n",
    "    module = model\n",
    "    mname_list = mname.split('.')\n",
    "    for mname in mname_list:\n",
    "        module = module._modules[mname]\n",
    "\n",
    "    return module\n",
    "\n",
    "\n",
    "def batchnorm_callibration(model, train_loader, n_batches = 200000//256, \n",
    "                           layer_name = None, device=\"cuda:0\"):\n",
    "    '''\n",
    "    Update batchnorm statistics for layers after layer_name\n",
    "    Parameters:\n",
    "    model                   -   Pytorch model\n",
    "    train_loader            -   Training dataset dataloader, Pytorch Dataloader\n",
    "    n_callibration_batches  -   Number of batchnorm callibration iterations, int\n",
    "    layer_name              -   Name of layer after which to update BN statistics, string or None\n",
    "                                (if None updates statistics for all BN layers)\n",
    "    device                  -   Device to store the model, string\n",
    "    '''\n",
    "    \n",
    "    # switch batchnorms into the mode, in which its statistics are updated\n",
    "    model.to(device).eval() \n",
    "    layer_passed = False\n",
    "    \n",
    "    if layer_name is not None:\n",
    "        #freeze batchnorms before replaced layer\n",
    "        for lname, l in model.named_modules():\n",
    "\n",
    "            if lname == layer_name:\n",
    "                layer_passed = True\n",
    "            \n",
    "            if (isinstance(l, nn.BatchNorm2d)) and layer_passed:\n",
    "                if layer_passed:\n",
    "                    l.train()\n",
    "                else:\n",
    "                    l.eval()\n",
    "\n",
    "    with torch.no_grad():            \n",
    "\n",
    "        for i, (data, _) in enumerate(train_loader):\n",
    "            _ = model(data.to(device))\n",
    "\n",
    "            if i > n_batches:\n",
    "                break\n",
    "            \n",
    "        del data\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a3d56c-8774-4cd8-928f-5960da007d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rank_for_layer(model, lname, decomposition, train_loader, val_loader, \n",
    "                             eval_func, bn_cal_func, bn_cal_n_iters, score_eps, \n",
    "                             max_rank, min_rank=3, grid_step=1, nx=1, device='cuda'):\n",
    "    '''\n",
    "    Find minimal decomposition rank for given acceptable target metric drop (uses binary search)\n",
    "    Parameters:\n",
    "    model           -   Initial model\n",
    "    lname           -   Name of layer to find decomposition rank, String\n",
    "    decomposition   -   Decomposition algorithm name, Options: (cp3, tucker2, svd), String\n",
    "    score_eps       -   Acceptable target metric drop, float\n",
    "    train_loader    -   Training dataset dataloader, Pytorch Dataloader\n",
    "    val_loader      -   Validation dataset dataloader, Pytorch Dataloader\n",
    "    eval_func       -   Function for model evaluation (returns target metric score,\n",
    "                        args: temp_model, val_loader, device), Python function\n",
    "    bn_cal_func     -   Function for batchnorm statistics calibration\n",
    "                        (args: emp_model, train_loader, lname, bn_cal_n_iters, device), Python function\n",
    "    bn_cal_n_iters  -   Number of batchnorm callibration iterations, int\n",
    "    max_rank        -   Upper bound of rank search, int\n",
    "    min_rank        -   Lower bound of rank search, int\n",
    "    grid_step       -   Rank search grid step (search for ranks multiple of grid_step)\n",
    "    nx              -   Minimal compression ratio for layer FLOPs, float\n",
    "    device          -   Device to store the model\n",
    "    \n",
    "    Output:\n",
    "    best_rank       -   Best rank for compression of given layer, int or None\n",
    "                        (if layer can not be compressed with given settings)\n",
    "    '''\n",
    "    \n",
    "    if decomposition not in ['cp3', 'tucker2', 'svd', 'cp3-epc']:\n",
    "        raise ValueError('Wrong decomposition name. Correct options: (cp3, tucker2, svd, cp3-epc)')\n",
    "    \n",
    "    curr_rank = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_max = max_rank // grid_step if max_rank // grid_step != 0 else 1\n",
    "    curr_min = min_rank // grid_step if min_rank // grid_step != 0 else 1\n",
    "    best_rank = None\n",
    "\n",
    "    n = int(np.log2(curr_max)) + 1\n",
    "    score_init = eval_func(model.to(device), val_loader, device=device)\n",
    "    \n",
    "    init_layer = get_layer_by_name(model, lname)\n",
    "    ch_ratio = init_layer.in_channels / init_layer.out_channels\n",
    "    \n",
    "    if curr_max < curr_min:\n",
    "        print(\"Layer can not be compressed with given grid step\")\n",
    "\n",
    "    for i in range(n):\n",
    "        print(\"Search iter {}: ranks (min, curr, max): ({}, {}, {})\".format(i, curr_min, curr_rank, \n",
    "                                                                            curr_max))\n",
    "\n",
    "        print(\"-------------------------\\n Compression step\")\n",
    "        \n",
    "        manual_rank = (int(curr_rank * ch_ratio), curr_rank) if decomposition=='tucker2' else curr_rank\n",
    "        \n",
    "        model_compr_kwargs = {lname: {'decomposition': decomposition,\n",
    "                                      'rank_selection': 'manual',\n",
    "                                      'manual_rank': [manual_rank],\n",
    "                                      'curr_compr_iter': 0}\n",
    "                              }\n",
    "        model_stats = FlopCo(model.to(device), img_size=(1, 3, 224, 224), device=device)\n",
    "\n",
    "        compressor = Compressor(copy.deepcopy(model.cpu()),\n",
    "                                model_stats,\n",
    "                                ft_every=3,\n",
    "                                nglobal_compress_iters=1,\n",
    "                                model_compr_kwargs = model_compr_kwargs,\n",
    "                               )\n",
    "        compressor.compression_step()\n",
    "\n",
    "        print(\"-------------------------\\n Calibration step\")\n",
    "        # calibrate batch norm statistics\n",
    "\n",
    "        compressor.compressed_model.to(device)\n",
    "        bn_cal_func(compressor.compressed_model, train_loader, layer_name=lname,\n",
    "                    n_batches=bn_cal_n_iters, device=device)\n",
    "\n",
    "        print(\"-------------------------\\n Test step\")\n",
    "\n",
    "        # eval model\n",
    "        score = eval_func(compressor.compressed_model, val_loader, device=device)\n",
    "        print('Current score: {}'.format(score))\n",
    "\n",
    "        # clear memory\n",
    "        del compressor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if score + score_eps < score_init:\n",
    "\n",
    "            if i == 0:\n",
    "                print(\"Bad layer to compress\")\n",
    "                if nx > 1:\n",
    "                    best_rank = curr_rank\n",
    "                break\n",
    "            else:\n",
    "                curr_min = curr_rank\n",
    "                curr_rank = curr_rank + (curr_max - curr_rank) // 2\n",
    "        else:\n",
    "            best_rank = curr_rank\n",
    "\n",
    "            curr_max = curr_rank\n",
    "            curr_rank = curr_rank - (curr_rank - curr_min) // 2\n",
    "\n",
    "    if best_rank is not None:\n",
    "        return best_rank * grid_step\n",
    "    else:\n",
    "        return best_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3caff0-2cc2-4d0a-878c-b0df2e8a38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_macs(model, layer_name, rank):\n",
    "    \"\"\"Returns original and reduced macs based on reduction rank\n",
    "    original macs = C_i * W_k * H_k * C_o * W_o * H_o\n",
    "    reduced macs = rank * C_i * W_i * H_i + rank**2 * W_k * H_k * W_o * H_o + rank * C_o * W_o * H_o\n",
    "    where:\n",
    "        C_i - number of input channels\n",
    "        C_o - number of output channels\n",
    "        W_o - width of the output image\n",
    "        H_o - height of the output image\n",
    "        W_i - width of the input image\n",
    "        H_i - height of the input image\n",
    "        W_k - width of the kernel\n",
    "        H_k - height of the kernel\n",
    "    \"\"\"\n",
    "    input_shape = output_shape = (1, 3, 224, 224)\n",
    "    layer = None\n",
    "    x = torch.rand(*input_shape)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for lname, layer in model.named_modules():\n",
    "            if not (isinstance(layer, nn.Conv2d) \n",
    "                    or isinstance(layer, nn.BatchNorm2d) \n",
    "                    or isinstance(layer, nn.MaxPool2d) \n",
    "                    or isinstance(layer, nn.ReLU)): continue\n",
    "            input_shape = x.shape\n",
    "            x = layer(x)\n",
    "            output_shape = x.shape\n",
    "            if lname == layer_name: break\n",
    "                \n",
    "    if not isinstance(layer, nn.Conv2d):\n",
    "        raise NotImplementedError('Function estimate_macs works only for Conv2d layers')\n",
    "        \n",
    "    orig_macs = layer.in_channels * layer.kernel_size[-1] * layer.kernel_size[-2] \\\n",
    "                * layer.out_channels * output_shape[-1] * output_shape[-2]\n",
    "    redc_macs = rank * layer.in_channels * input_shape[-1] * input_shape[-2] \\\n",
    "                + rank**2 * layer.kernel_size[-1] * layer.kernel_size[-2] * output_shape[-1] * output_shape[-2] \\\n",
    "                + rank * layer.out_channels * output_shape[-1] * output_shape[-2]\n",
    "    \n",
    "    return orig_macs, redc_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32bea15a-d330-4459-8fe7-21dd1e3a5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_imagenet_train_val_loaders(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/',\n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       val_perc=0.04,\n",
    "                                       shuffle=True,\n",
    "                                       random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb72086-dd36-4a29-90e4-660e4dad6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_imagenet_test_loader(data_root='/gpfs/gpfs0/k.sobolev/ILSVRC-12/', \n",
    "                                       batch_size=500,\n",
    "                                       num_workers=4,\n",
    "                                       pin_memory=True,\n",
    "                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061221b7-c554-471f-9155-8650290fe324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47786c80-2768-4968-811a-25881075aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15afa518e47476db28a51c8648479a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48e241b-b0b0-47e0-8a57-c870f0d6fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = FlopCo(model, img_size=(1, 3, 224, 224), device=device)\n",
    "all_lnames = list(model_stats.flops.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80251c0-1eb1-4fe2-b716-733b3d0af537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of layer names to be compressed\n",
    "lnames_to_compress = [k for k in all_lnames if model_stats.ltypes[k]['type'] == nn.Conv2d \\\n",
    "                      and k != 'conv1' and 'downsample' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f42b41c9-32d2-4c05-b69b-b328d2a0d466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layer1.0.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 134\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 134\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 134\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "Shape: torch.Size([64, 64, 3, 3])\n",
      "Rank: 134\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "Shape: torch.Size([128, 64, 3, 3])\n",
      "Rank: 183\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 278\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 278\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "Shape: torch.Size([128, 128, 3, 3])\n",
      "Rank: 278\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "Shape: torch.Size([256, 128, 3, 3])\n",
      "Rank: 375\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 566\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 566\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "Shape: torch.Size([256, 256, 3, 3])\n",
      "Rank: 566\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "Shape: torch.Size([512, 256, 3, 3])\n",
      "Rank: 759\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 1141\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 1141\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "Shape: torch.Size([512, 512, 3, 3])\n",
      "Rank: 1141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_ranks = {}\n",
    "\n",
    "for lname in lnames_to_compress:\n",
    "    layer_shape = get_layer_by_name(model, lname).weight.shape\n",
    "    print('Layer:', lname)\n",
    "    print('Shape:', layer_shape)\n",
    "    rank = estimate_rank_for_compression_rate(layer_shape, rate=2,\n",
    "                                              tensor_format='cp3')\n",
    "    print('Rank:', rank)\n",
    "    print()\n",
    "    max_ranks[lname] = rank\n",
    "    \n",
    "saved_ranks = {k: None for k in all_lnames}\n",
    "min_ranks = {k: 10 for k in max_ranks.keys()}\n",
    "curr_ranks = copy.deepcopy(max_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe0fef51-5a94-47b1-9987-e3f1e941ec2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2e9df99fcf456b9bd39894537f31de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search iter 0: ranks (min, curr, max): (10, 134, 134)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [134], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1883dc309c4d3c9b5dbf757e283110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7946470588235294\n",
      "Search iter 1: ranks (min, curr, max): (10, 72, 134)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [72], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c6a77641794a00b3769cac9aae0fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7894705882352941\n",
      "Search iter 2: ranks (min, curr, max): (72, 103, 134)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [103], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137885e6faf546f9af8c50abfb44c9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.793078431372549\n",
      "Search iter 3: ranks (min, curr, max): (72, 88, 103)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [88], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfcfd8877ef4fda920c1001d2a0c91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.792843137254902\n",
      "Search iter 4: ranks (min, curr, max): (72, 80, 88)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [80], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15cd525f4cd45b19a7e32bce1efc60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.787\n",
      "Search iter 5: ranks (min, curr, max): (80, 84, 88)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [84], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa93ea171d9d4fd69705d2809179fe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7919607843137255\n",
      "Search iter 6: ranks (min, curr, max): (80, 82, 84)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [82], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30a0b527bdb490395c82be2cbbcccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7904901960784314\n",
      "Search iter 7: ranks (min, curr, max): (82, 83, 84)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer1.0.conv1 {'decomposition': 'cp3-epc', 'rank_selection': 'manual', 'manual_rank': [83], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n",
      "Use numpy backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Calibration step\n",
      "-------------------------\n",
      " Test step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f555acd800ff4ad2ae2f1451f626eecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score: 0.7907058823529411\n",
      "CPU times: user 31min 5s, sys: 1min 3s, total: 32min 8s\n",
      "Wall time: 48min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "find_best_rank_for_layer(model, \n",
    "                         lname='layer1.0.conv1', \n",
    "                         decomposition='cp3-epc', \n",
    "                         train_loader=train_loader, \n",
    "                         val_loader=val_loader, \n",
    "                         eval_func=accuracy,\n",
    "                         bn_cal_func=batchnorm_callibration, \n",
    "                         bn_cal_n_iters=1, \n",
    "                         score_eps=0.003,\n",
    "                         max_rank=max_ranks['layer1.0.conv1'], \n",
    "                         min_rank=min_ranks['layer1.0.conv1'],\n",
    "                         grid_step=1, \n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7bf644b-f110-4fa5-82dc-cdb3eaa6660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2571885850694444"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer1.0.conv1', 65)\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114452bf-4852-48cb-a704-1aafe6a579f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0143229166666665"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer1.0.conv1', 84)\n",
    "redc_macs / orig_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c32a8d-06d8-443b-b72e-7ea555bf3dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d72b6745b44dd285ae434867f6cac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search iter 0: ranks (min, curr, max): (10, 1141, 1141)\n",
      "-------------------------\n",
      " Compression step\n",
      "layer4.1.conv2 {'decomposition': 'cp3', 'rank_selection': 'manual', 'manual_rank': [1141], 'curr_compr_iter': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use numpy backend\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lname = 'layer4.1.conv2'\n",
    "find_best_rank_for_layer(model, \n",
    "                         lname=lname, \n",
    "                         decomposition='cp3', \n",
    "                         train_loader=train_loader, \n",
    "                         val_loader=val_loader, \n",
    "                         eval_func=accuracy,\n",
    "                         bn_cal_func=batchnorm_callibration, \n",
    "                         bn_cal_n_iters=1, \n",
    "                         score_eps=0.003,\n",
    "                         max_rank=max_ranks[lname], \n",
    "                         min_rank=min_ranks[lname],\n",
    "                         grid_step=1, \n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8693c-4cba-45e2-a9c5-612eedb540e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_macs, redc_macs = estimate_macs(model, 'layer4.1.conv2', 65)\n",
    "redc_macs / orig_macs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark20",
   "language": "python",
   "name": "mark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
