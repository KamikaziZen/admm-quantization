{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176e4c93-1b61-491c-92af-be84a105574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce4e6c-e12b-4a07-86d8-ce03fdd6efa8",
   "metadata": {},
   "source": [
    "![Original-ResNet-18-Architecture.png](Original-ResNet-18-Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700ac8cf-edd0-4b9d-9e11-f6ecab0ddc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/d.cherniuk/.conda/mark23/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model = resnet18(pretrained=True)\n",
    "orig_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1065d8e8-4456-43c3-b4c9-e24175832a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model.layer2[0].downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd014fe-0fc2-4cb6-902b-00688a1ccdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 3, 7, 7])\n",
      "Flattened Shape: torch.Size([64, 3, 49])\n",
      "Parameters: 9408\n",
      "Original MACs: 118013952\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [81, 40, 20, 16, 13, 11, 10]\n",
      "\n",
      "Layer: layer1.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Reduced MACs(%): [99.97, 49.8, 24.9, 19.7, 16.35, 14.12, 12.26]\n",
      "\n",
      "Layer: layer1.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Reduced MACs(%): [99.97, 49.8, 24.9, 19.7, 16.35, 14.12, 12.26]\n",
      "\n",
      "Layer: layer1.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Reduced MACs(%): [99.97, 49.8, 24.9, 19.7, 16.35, 14.12, 12.26]\n",
      "\n",
      "Layer: layer1.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([64, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([64, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 64, 56, 56])\n",
      "Parameters: 36864\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [269, 134, 67, 53, 44, 38, 33]\n",
      "Reduced MACs(%): [99.97, 49.8, 24.9, 19.7, 16.35, 14.12, 12.26]\n",
      "\n",
      "Layer: layer2.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 64, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 64, 9])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 73728\n",
      "Original MACs: 57802752\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [366, 183, 91, 73, 61, 52, 45]\n",
      "Reduced MACs(%): [195.09, 97.55, 48.51, 38.91, 32.52, 27.72, 23.99]\n",
      "\n",
      "Layer: layer2.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Reduced MACs(%): [99.92, 49.96, 24.98, 19.95, 16.53, 14.2, 12.4]\n",
      "\n",
      "Layer: layer2.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 64, 1, 1])\n",
      "Flattened Shape: torch.Size([128, 64])\n",
      "Input shape: torch.Size([1, 64, 56, 56])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 8192\n",
      "Original MACs: 6422528\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [42, 21, 10, 8, 7, 6, 5]\n",
      "\n",
      "Layer: layer2.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Reduced MACs(%): [99.92, 49.96, 24.98, 19.95, 16.53, 14.2, 12.4]\n",
      "\n",
      "Layer: layer2.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([128, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([128, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 128, 28, 28])\n",
      "Parameters: 147456\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [556, 278, 139, 111, 92, 79, 69]\n",
      "Reduced MACs(%): [99.92, 49.96, 24.98, 19.95, 16.53, 14.2, 12.4]\n",
      "\n",
      "Layer: layer3.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 128, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 128, 9])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 294912\n",
      "Original MACs: 57802752\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [750, 375, 187, 150, 125, 107, 93]\n",
      "Reduced MACs(%): [197.6, 98.8, 49.27, 39.52, 32.93, 28.19, 24.5]\n",
      "\n",
      "Layer: layer3.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Reduced MACs(%): [99.99, 50.0, 25.0, 19.96, 16.61, 14.22, 12.45]\n",
      "\n",
      "Layer: layer3.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 128, 1, 1])\n",
      "Flattened Shape: torch.Size([256, 128])\n",
      "Input shape: torch.Size([1, 128, 28, 28])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 32768\n",
      "Original MACs: 6422528\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [85, 42, 21, 17, 14, 12, 10]\n",
      "\n",
      "Layer: layer3.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Reduced MACs(%): [99.99, 50.0, 25.0, 19.96, 16.61, 14.22, 12.45]\n",
      "\n",
      "Layer: layer3.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([256, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([256, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 256, 14, 14])\n",
      "Parameters: 589824\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [1132, 566, 283, 226, 188, 161, 141]\n",
      "Reduced MACs(%): [99.99, 50.0, 25.0, 19.96, 16.61, 14.22, 12.45]\n",
      "\n",
      "Layer: layer4.0.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 256, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 256, 9])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 1179648\n",
      "Original MACs: 57802752\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [1518, 759, 379, 303, 253, 216, 189]\n",
      "Reduced MACs(%): [198.81, 99.41, 49.64, 39.68, 33.14, 28.29, 24.75]\n",
      "\n",
      "Layer: layer4.0.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Reduced MACs(%): [99.96, 49.96, 24.96, 19.97, 16.64, 14.27, 12.48]\n",
      "\n",
      "Layer: layer4.0.downsample\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 256, 1, 1])\n",
      "Flattened Shape: torch.Size([512, 256])\n",
      "Input shape: torch.Size([1, 256, 14, 14])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 131072\n",
      "Original MACs: 6422528\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [170, 85, 42, 34, 28, 24, 21]\n",
      "\n",
      "Layer: layer4.1.conv1\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Reduced MACs(%): [99.96, 49.96, 24.96, 19.97, 16.64, 14.27, 12.48]\n",
      "\n",
      "Layer: layer4.1.conv2\n",
      "bias: False\n",
      "Original Shape: torch.Size([512, 512, 3, 3])\n",
      "Flattened Shape: torch.Size([512, 512, 9])\n",
      "Input shape: torch.Size([1, 512, 7, 7])\n",
      "Output shape: torch.Size([1, 512, 7, 7])\n",
      "Parameters: 2359296\n",
      "Original MACs: 115605504\n",
      "Reduction rates: [1, 2, 4, 5, 6, 7, 8]\n",
      "Reduction ranks: [2283, 1141, 570, 456, 380, 326, 285]\n",
      "Reduced MACs(%): [99.96, 49.96, 24.96, 19.97, 16.64, 14.27, 12.48]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "REDUCTION_RATES = [1, 2, 4, 5, 6, 7, 8]\n",
    "rank_map = {}\n",
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# original macs = C_i * W_k * H_k * C_o * W_o * H_o\n",
    "# reduced macs = rank * C_i * W_i * H_i + rank * W_k * H_k * W_o * H_o + rank * C_o * W_o * H_o\n",
    "layer = orig_model.conv1\n",
    "weight = orig_model.conv1.weight.detach()\n",
    "bias = orig_model.conv1.bias\n",
    "with torch.no_grad(): y = layer(dummy_input)\n",
    "print('Layer: conv1')\n",
    "print('bias:', bias is not None)\n",
    "print('Original Shape:', weight.shape)\n",
    "weight = weight.reshape((weight.shape[0], weight.shape[1], -1))\n",
    "print('Flattened Shape:', weight.shape)\n",
    "print('Input shape:', dummy_input.shape)\n",
    "print()\n",
    "\n",
    "print('Parameters:', weight.numel())\n",
    "orig_macs = torch.tensor(weight.shape).prod() * y.shape[-1] * y.shape[-2]\n",
    "print('Original MACs:', orig_macs.item())\n",
    "# print('Feasible ranks <', X.numel()/sum(list(X.shape))/REDUCTION_RATE)\n",
    "ranks = list(int(weight.numel()/sum(list(weight.shape))/rate) for rate in REDUCTION_RATES)\n",
    "print('Reduction rates:', REDUCTION_RATES)\n",
    "print('Reduction ranks:', ranks)\n",
    "print()\n",
    "rank_map['conv1'] = ranks\n",
    "y = orig_model.maxpool(y)\n",
    "\n",
    "for layer_name in ['layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', \n",
    "                   'layer2.0.conv1', 'layer2.0.conv2', 'layer2.0.downsample', 'layer2.1.conv1', 'layer2.1.conv2',\n",
    "                   'layer3.0.conv1', 'layer3.0.conv2', 'layer3.0.downsample', 'layer3.1.conv1', 'layer3.1.conv2',\n",
    "                   'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample', 'layer4.1.conv1', 'layer4.1.conv2']:\n",
    "    lname, lidx, ltype = layer_name.split('.')\n",
    "    lidx = int(lidx)\n",
    "    layer = orig_model.__getattr__(lname)[lidx].__getattr__(ltype)\n",
    "    if ltype == 'downsample': layer = layer[0]\n",
    "    weight = layer.weight.detach()\n",
    "    bias = orig_model.conv1.bias\n",
    "    print('Layer:', layer_name)\n",
    "    print('bias:', bias is not None)\n",
    "    print('Original Shape:', weight.shape)\n",
    "    weight = weight.reshape((weight.shape[0], weight.shape[1], -1))\n",
    "    if ltype == 'downsample': weight = weight.reshape((weight.shape[0], weight.shape[1]))\n",
    "    print('Flattened Shape:', weight.shape)\n",
    "    \n",
    "    c1 = layer.in_channels * y.shape[-1] * y.shape[-2]\n",
    "    if layer_name.endswith('.0.conv1'): \n",
    "        print('Input shape:', y.shape)\n",
    "        with torch.no_grad(): y = layer(y)\n",
    "        print('Output shape:', y.shape)\n",
    "    elif ltype == 'downsample':\n",
    "        print('Input shape:', res.shape)\n",
    "        with torch.no_grad(): print('Output shape:', layer(res).shape)\n",
    "    else:\n",
    "        print('Input shape:', y.shape)\n",
    "        print('Output shape:', y.shape)\n",
    "    c2 = layer.kernel_size[0] * layer.kernel_size[1] * y.shape[-1] * y.shape[-2]\n",
    "    c3 = layer.out_channels * y.shape[-1] * y.shape[-2]\n",
    "    if layer_name.endswith('.1.conv2'):\n",
    "        res = y\n",
    "    \n",
    "    print('Parameters:', weight.numel())\n",
    "    orig_macs = torch.tensor(weight.shape).prod() * y.shape[-1] * y.shape[-2]\n",
    "    print('Original MACs:', orig_macs.item())\n",
    "    ranks = list(int(weight.numel()/sum(list(weight.shape))/rate) for rate in REDUCTION_RATES)\n",
    "    print('Reduction rates:', REDUCTION_RATES)\n",
    "    print('Reduction ranks:', ranks)\n",
    "    if ltype != 'downsample': \n",
    "        macs = [(rank * (c1 + c2 + c3) * 100/orig_macs).item() for rank in ranks]\n",
    "        print('Reduced MACs(%):', [round(mac, 2) for mac in macs])\n",
    "    print()\n",
    "    rank_map[layer_name] = ranks\n",
    "    \n",
    "\n",
    "# X = orig_model.fc.weight.detach()\n",
    "# bias = orig_model.conv1.bias\n",
    "# print('Layer: fc')\n",
    "# print('Original Shape:', X.shape)\n",
    "# print('Parameters:', X.numel())\n",
    "# print('bias:', bias is not None)\n",
    "# # print('Feasible rank < ', X.numel()/sum(list(X.shape))/rate)\n",
    "# ranks = list(int(X.numel()/sum(list(X.shape))/rate) for rate in REDUCTION_RATES)\n",
    "# print('Feasible ranks = ', ranks)\n",
    "# rank_map['fc'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfb7975-0ce6-473e-b6d3-f29f90af446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': [81, 40, 20, 16, 13, 11, 10],\n",
       " 'layer1.0.conv1': [269, 134, 67, 53, 44, 38, 33],\n",
       " 'layer1.0.conv2': [269, 134, 67, 53, 44, 38, 33],\n",
       " 'layer1.1.conv1': [269, 134, 67, 53, 44, 38, 33],\n",
       " 'layer1.1.conv2': [269, 134, 67, 53, 44, 38, 33],\n",
       " 'layer2.0.conv1': [366, 183, 91, 73, 61, 52, 45],\n",
       " 'layer2.0.conv2': [556, 278, 139, 111, 92, 79, 69],\n",
       " 'layer2.0.downsample': [42, 21, 10, 8, 7, 6, 5],\n",
       " 'layer2.1.conv1': [556, 278, 139, 111, 92, 79, 69],\n",
       " 'layer2.1.conv2': [556, 278, 139, 111, 92, 79, 69],\n",
       " 'layer3.0.conv1': [750, 375, 187, 150, 125, 107, 93],\n",
       " 'layer3.0.conv2': [1132, 566, 283, 226, 188, 161, 141],\n",
       " 'layer3.0.downsample': [85, 42, 21, 17, 14, 12, 10],\n",
       " 'layer3.1.conv1': [1132, 566, 283, 226, 188, 161, 141],\n",
       " 'layer3.1.conv2': [1132, 566, 283, 226, 188, 161, 141],\n",
       " 'layer4.0.conv1': [1518, 759, 379, 303, 253, 216, 189],\n",
       " 'layer4.0.conv2': [2283, 1141, 570, 456, 380, 326, 285],\n",
       " 'layer4.0.downsample': [170, 85, 42, 34, 28, 24, 21],\n",
       " 'layer4.1.conv1': [2283, 1141, 570, 456, 380, 326, 285],\n",
       " 'layer4.1.conv2': [2283, 1141, 570, 456, 380, 326, 285]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a69b3b-2594-4d95-ae04-65faa9393a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark23",
   "language": "python",
   "name": "mark23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
